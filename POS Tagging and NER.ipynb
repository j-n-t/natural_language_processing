{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging, Syntactic Dependency Parsing and NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll demonstrate how we can perform **part-of-speech tagging (POS), syntactic dependency parsing and named entity recognition (NER) with spaCy**.\n",
    "\n",
    "For this, we will use two different books, both freely available on the [Project Gutenberg website](https://www.gutenberg.org):\n",
    "\n",
    "* \"Flatland: A Romance of Many Dimensions\", by Edwin Abbott Abbott\n",
    "<br><br>\n",
    "* Charles Darwin's seminal book \"On the Origin of Species by Means of Natural Selection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text/flatland.txt', encoding='utf8') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spaCy, the `Doc` class is a container for accessing linguistic annotations. Let's explore the `doc` object we've just created via the `nlp` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences of our doc\n",
    "\n",
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence example\n",
    "\n",
    "sentences[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of sentences\n",
    "\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span of our sentence\n",
    "\n",
    "sentences[11][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extract POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can access the **text, coarse-grained POS tags, fine-grained POS tags and the description of these fine-grained POS tags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text and POS tag\n",
    "\n",
    "for token in sentences[11][0:5]:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text, POS tag, fine-grained POS tag and description for whole sentence\n",
    "\n",
    "for token in sentences[11]:\n",
    "    print(f'{token.text:{15}} {token.pos_:{8}} {token.tag_:{8}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily count the total number of each POS tag in our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's order them and replace their ID's by the corresponding strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key ,value in sorted(POS_counts.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f'{doc.vocab[key].text:{8}}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouns and punctuation marks are the most common POS tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  Extract syntactic dependency labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have access to the **syntactic dependency labels** and their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text and dependency labels\n",
    "\n",
    "for token in sentences[11][0:5]:\n",
    "    print(token.text, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text, dependency labels and description for whole sentence\n",
    "\n",
    "for token in sentences[11]:\n",
    "    print(f'{token.text:{15}} {token.dep_:{10}} {spacy.explain(token.dep_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **syntactic dependency label** describes the type of syntactic relation between two words in a sentence. For each pair of words, one word is the **syntactic governor, also called the head**, and the other is the **dependent, also called the child**.\n",
    "\n",
    "Each word in a sentence has exactly one head: a word can be a child to only one head, but a given word can act as a head in none, one or several pairs.\n",
    "\n",
    "Let's see a simple example of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text, dependency label and head\n",
    "\n",
    "for token in sentences[11][0:5]:\n",
    "    print(f'{token.text:{10}} {token.dep_:{10}} {token.head.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROOT label marks the token whose head is itsell - in this case the verb 'call'. This verb is also the head for the words 'I' and 'Flatland'.\n",
    "\n",
    "We can also visualize the relationship between our words in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Visualize syntactic dependency parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering only our first 5 tokens\n",
    "\n",
    "displacy.render(list(doc.sents)[11][:5], style='dep', options={'compact': True, 'bg': '#09a3d5', 'color': 'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we can do is to export this visualization to a file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save visualization as an html page\n",
    "\n",
    "# page = True to render as a full HTML page\n",
    "# jupyter = False to override jupyter detection\n",
    "html_page = displacy.render(list(doc.sents)[11][:5], style='dep', page=True, jupyter=False, options={'compact': True, 'bg': '#09a3d5', 'color': 'white'})\n",
    "\n",
    "# output directory name\n",
    "output_dir = 'dependency_vis'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "with open(output_dir+'/flatland.html', 'w', encoding='utf8') as f:\n",
    "    f.write(html_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recoginition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text/origin_of_species.txt', encoding='utf8') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In considering the Origin of Species, it is quite conceivable that a\n",
       "naturalist, reflecting on the mutual affinities of organic beings, on their\n",
       "embryological relations, their geographical distribution, geological\n",
       "succession, and other such facts, might come to the conclusion that each\n",
       "species had not been independently created, but had descended, like\n",
       "varieties, from other species."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[179]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Recognize named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display entity info\n",
    "\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+': '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Origin of Species: WORK_OF_ART - Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(sentences[179])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevertheless, such a conclusion, even if\n",
       "well founded, would be unsatisfactory, until it could be shown how the\n",
       "innumerable species inhabiting this world have been modified, so as to\n",
       "acquire that perfection of structure and coadaptation which most justly\n",
       "excites our admiration."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "show_ents(sentences[180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Identify sentences with 'n' or more named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_n_ents(doc, n=1):\n",
    "    list_sentences = [sentence for sentence in doc.sents if len(sentence.ents) >= n]\n",
    "    return list_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences with 4 or more named entities\n",
    "\n",
    "ner_sentences = sents_n_ents(doc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 264 sentences with 4 or more named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Recognize named entities in one of these sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Pigeons were much valued by Akber Khan\n",
       "in India, about the year 1600; never less than 20,000 pigeons were taken\n",
       "with the court."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_sentences[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akber Khan: PERSON - People, including fictional\n",
      "India: GPE - Countries, cities, states\n",
      "about the year 1600: DATE - Absolute or relative dates or periods\n",
      "less than 20,000: CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "show_ents(ner_sentences[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Visualize named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot; Pigeons were much valued by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akber Khan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</br>in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about the year 1600\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "; never \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    less than 20,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " pigeons were taken\n",
       "with the court. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(ner_sentences[14], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Add a named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if that\n",
       "between America and Europe is ample, will that between the Continent and\n",
       "the Azores, or Madeira, or the Canaries, or Ireland, be sufficient?"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_sentences[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America: GPE - Countries, cities, states\n",
      "Europe: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Continent: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Canaries: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Ireland: GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(ner_sentences[24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, [Azores](https://en.wikipedia.org/wiki/Azores) and [Madeira](https://en.wikipedia.org/wiki/Madeira) are not recognized as a named entity - LOC - by spaCy. Let's change that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this, we need to know the position - the indices - of our tokens of interest in our `doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_i_madeira = [token.i for token in doc if token.text == 'Madeira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_i_azores = [token.i for token in doc if token.text == 'Azores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that for our sentence of interest the token \"Madeira\" is the third token after the token \"Azores\", we can use that information to identify our indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_i=[]\n",
    "\n",
    "for token_i in token_i_azores:\n",
    "    if token_i + 3 in token_i_madeira:\n",
    "        possible_i.append(token_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20728]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, there's only one possibility. Let's see if it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azores, or Madeira, or the Canaries, or Ireland, be sufficient?"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20728:20743]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be our sentence! Let's confirm our indices and add a named entity to these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azores"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20728]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madeira"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "azores_ent = Span(doc, 20728, 20729, label='LOC')\n",
    "madeira_ent = Span(doc, 20731, 20732, label='LOC')\n",
    "\n",
    "doc.ents = list(doc.ents) + [azores_ent, madeira_ent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America: GPE - Countries, cities, states\n",
      "Europe: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Continent: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Azores: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Madeira: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Canaries: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Ireland: GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(ner_sentences[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">if that</br>between \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Europe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " is ample, will that between the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Continent\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and</br>the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Azores\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madeira\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Canaries\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ireland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", be sufficient? </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(ner_sentences[24], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this means that Azores and Madeira will be identified as entities in this sentence, but not in other occurrences throughout our document. In order to change this, we'll use spaCy's **PhraseMatcher**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Add a named entity to all occurences of a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the matcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create match patterns and add them to the matcher\n",
    "\n",
    "pattern1 = nlp(\"Azores\")\n",
    "pattern2 = nlp(\"Madeira\")\n",
    "\n",
    "matcher.add('PATTERN1', None, pattern1)\n",
    "matcher.add('PATTERN2', None, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN2:  20570 --> 20571  (Madeira)\n",
      "PATTERN1:  20728 --> 20729  (Azores)\n",
      "PATTERN2:  20731 --> 20732  (Madeira)\n",
      "PATTERN2:  21980 --> 21981  (Madeira)\n",
      "PATTERN2:  42782 --> 42783  (Madeira)\n",
      "PATTERN2:  53622 --> 53623  (Madeira)\n",
      "PATTERN2:  53690 --> 53691  (Madeira)\n",
      "PATTERN2:  53731 --> 53732  (Madeira)\n",
      "PATTERN2:  53792 --> 53793  (Madeira)\n",
      "PATTERN2:  53895 --> 53896  (Madeira)\n",
      "PATTERN2:  54434 --> 54435  (Madeira)\n",
      "PATTERN1:  55446 --> 55447  (Azores)\n",
      "PATTERN2:  120501 --> 120502  (Madeira)\n",
      "PATTERN2:  129997 --> 129998  (Madeira)\n",
      "PATTERN1:  138931 --> 138932  (Azores)\n",
      "PATTERN2:  149084 --> 149085  (Madeira)\n",
      "PATTERN2:  149475 --> 149476  (Madeira)\n",
      "PATTERN2:  149517 --> 149518  (Madeira)\n",
      "PATTERN2:  149608 --> 149609  (Madeira)\n",
      "PATTERN2:  149716 --> 149717  (Madeira)\n",
      "PATTERN2:  150302 --> 150303  (Madeira)\n",
      "PATTERN1:  150305 --> 150306  (Azores)\n",
      "PATTERN2:  153942 --> 153943  (Madeira)\n",
      "PATTERN2:  153984 --> 153985  (Madeira)\n",
      "PATTERN1:  187445 --> 187446  (Azores)\n",
      "PATTERN2:  187645 --> 187646  (Madeira)\n",
      "PATTERN2:  187754 --> 187755  (Madeira)\n",
      "PATTERN1:  187916 --> 187917  (Azores)\n",
      "PATTERN2:  190372 --> 190373  (Madeira)\n",
      "PATTERN1:  190384 --> 190385  (Azores)\n",
      "PATTERN2:  190421 --> 190422  (Madeira)\n",
      "PATTERN2:  191242 --> 191243  (Madeira)\n",
      "PATTERN2:  191612 --> 191613  (Madeira)\n",
      "PATTERN2:  191640 --> 191641  (Madeira)\n",
      "PATTERN2:  193779 --> 193780  (Madeira)\n",
      "PATTERN1:  195084 --> 195085  (Azores)\n",
      "PATTERN2:  195260 --> 195261  (Madeira)\n",
      "PATTERN2:  195315 --> 195316  (Madeira)\n",
      "PATTERN2:  195610 --> 195611  (Madeira)\n",
      "PATTERN2:  195632 --> 195633  (Madeira)\n"
     ]
    }
   ],
   "source": [
    "# apply the matcher to our doc\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(doc.vocab.strings[match_id]+': ', str(start)+' --> '+str(end), ' ('+doc[start:end].text+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now identified all the occurences of our tokens \"Azores\" and \"Madeira\". Let's add a named entity to all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new entities excluding the ones we already added to avoid conflicts\n",
    "\n",
    "new_ents = [Span(doc, start, end, label='LOC') for _, start, end in matcher(doc) \n",
    "            if (start != 20728) and (start != 20731)]\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, several occurrences of the token \"Madeira\" were identified with the named entity \"ORG\". Since we cannot have overlapping entities, let's try to do this only for the \"Azores\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the matcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create match patterns and add them to the matcher\n",
    "\n",
    "pattern = nlp(\"Azores\")\n",
    "\n",
    "matcher.add('PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN:  20728 --> 20729  (Azores)\n",
      "PATTERN:  55446 --> 55447  (Azores)\n",
      "PATTERN:  138931 --> 138932  (Azores)\n",
      "PATTERN:  150305 --> 150306  (Azores)\n",
      "PATTERN:  187445 --> 187446  (Azores)\n",
      "PATTERN:  187916 --> 187917  (Azores)\n",
      "PATTERN:  190384 --> 190385  (Azores)\n",
      "PATTERN:  195084 --> 195085  (Azores)\n"
     ]
    }
   ],
   "source": [
    "# apply the matcher to our doc\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(doc.vocab.strings[match_id]+': ', str(start)+' --> '+str(end), ' ('+doc[start:end].text+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new entities excluding the one we already added to avoid conflicts\n",
    "# there's also other conflicting doc.ents with start=187916 and 190384\n",
    "\n",
    "new_ents = [Span(doc, start, end, label='LOC') for _, start, end in matcher(doc) \n",
    "            if (start != 20728) and (start !=187916) and (start !=190384)]\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr. Thwaites informs me that he\n",
       "has observed similar facts in Ceylon, and analogous observations have been\n",
       "made by Mr. H. C. Watson on European species of plants brought from the\n",
       "Azores to England."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for pattern with start=55446\n",
    "\n",
    "doc[55411:55450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thwaites: PERSON - People, including fictional\n",
      "Ceylon: GPE - Countries, cities, states\n",
      "H. C. Watson: PERSON - People, including fictional\n",
      "European: NORP - Nationalities or religious or political groups\n",
      "Azores: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "England: GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc[55411:55450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thwaites\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " informs me that he</br>has observed similar facts in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ceylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and analogous observations have been</br>made by Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    H. C. Watson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " species of plants brought from the</br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Azores\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc[55411:55450], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the \"Azores\" token is now identified as a LOC - Non-GPE locations, mountain ranges, bodies of water."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative, we could have also customized the text-processing pipeline by **updating the NER pipeline component**. In order to do this, we would need to prepare some training data with annotations that the model could learn from."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
