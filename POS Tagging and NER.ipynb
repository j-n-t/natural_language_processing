{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging and Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll demonstrate how we can perform **part-of-speech tagging (POS) and named entity recognition (NER) with spaCy**.\n",
    "\n",
    "For this, we will use two different books, both freely available on the [Project Gutenberg website](https://www.gutenberg.org):\n",
    "\n",
    "* \"Flatland: A Romance of Many Dimensions\", by Edwin Abbott Abbott\n",
    "<br><br>\n",
    "* Charles Darwin's seminal book \"On the Origin of Species by Means of Natural Selection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text/flatland.txt', encoding='utf8') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In spaCy, the `Doc` class is a container for accessing linguistic annotations. Let's explore the `doc` object we've just created via the `nlp` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences of our doc\n",
    "\n",
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I call our world Flatland, not because we call it so, but to make its\n",
       "nature clearer to you, my happy readers, who are privileged to live in\n",
       "Space.\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence example\n",
    "\n",
    "sentences[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of sentences\n",
    "\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I call our world Flatland"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# span of our sentence\n",
    "\n",
    "sentences[11][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Extract POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can access the **text, POS tags, fine-grained POS tags and the description of these fine-grained POS tags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "call VERB\n",
      "our DET\n",
      "world NOUN\n",
      "Flatland PROPN\n"
     ]
    }
   ],
   "source": [
    "# text and POS tag\n",
    "\n",
    "for token in sentences[11][0:5]:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I               PRON     PRP      pronoun, personal\n",
      "call            VERB     VBP      verb, non-3rd person singular present\n",
      "our             DET      PRP$     pronoun, possessive\n",
      "world           NOUN     NN       noun, singular or mass\n",
      "Flatland        PROPN    NNP      noun, proper singular\n",
      ",               PUNCT    ,        punctuation mark, comma\n",
      "not             PART     RB       adverb\n",
      "because         SCONJ    IN       conjunction, subordinating or preposition\n",
      "we              PRON     PRP      pronoun, personal\n",
      "call            VERB     VBP      verb, non-3rd person singular present\n",
      "it              PRON     PRP      pronoun, personal\n",
      "so              ADV      RB       adverb\n",
      ",               PUNCT    ,        punctuation mark, comma\n",
      "but             CCONJ    CC       conjunction, coordinating\n",
      "to              PART     TO       infinitival \"to\"\n",
      "make            VERB     VB       verb, base form\n",
      "its             DET      PRP$     pronoun, possessive\n",
      "\n",
      "               SPACE    _SP      None\n",
      "nature          NOUN     NN       noun, singular or mass\n",
      "clearer         ADJ      JJR      adjective, comparative\n",
      "to              ADP      IN       conjunction, subordinating or preposition\n",
      "you             PRON     PRP      pronoun, personal\n",
      ",               PUNCT    ,        punctuation mark, comma\n",
      "my              DET      PRP$     pronoun, possessive\n",
      "happy           ADJ      JJ       adjective\n",
      "readers         NOUN     NNS      noun, plural\n",
      ",               PUNCT    ,        punctuation mark, comma\n",
      "who             PRON     WP       wh-pronoun, personal\n",
      "are             AUX      VBP      verb, non-3rd person singular present\n",
      "privileged      ADJ      JJ       adjective\n",
      "to              PART     TO       infinitival \"to\"\n",
      "live            VERB     VB       verb, base form\n",
      "in              ADP      IN       conjunction, subordinating or preposition\n",
      "\n",
      "               SPACE    _SP      None\n",
      "Space           PROPN    NNP      noun, proper singular\n",
      ".               PUNCT    .        punctuation mark, sentence closer\n",
      "\n",
      "\n",
      "              SPACE    _SP      None\n"
     ]
    }
   ],
   "source": [
    "# text, POS tag, fine-grained POS tag and description for whole sentence\n",
    "\n",
    "for token in sentences[11]:\n",
    "    print(f'{token.text:{15}} {token.pos_:{8}} {token.tag_:{8}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily count the total number of each POS tag in our document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{96: 2310,\n",
       " 103: 2748,\n",
       " 95: 2313,\n",
       " 90: 4880,\n",
       " 97: 4955,\n",
       " 87: 1540,\n",
       " 84: 2339,\n",
       " 85: 4053,\n",
       " 92: 5149,\n",
       " 89: 1501,\n",
       " 100: 4026,\n",
       " 93: 451,\n",
       " 94: 845,\n",
       " 98: 968,\n",
       " 86: 2003,\n",
       " 91: 55,\n",
       " 99: 2,\n",
       " 101: 15}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's order them and replace their ID's by the corresponding strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN    : 5149\n",
      "PUNCT   : 4955\n",
      "DET     : 4880\n",
      "ADP     : 4053\n",
      "VERB    : 4026\n",
      "SPACE   : 2748\n",
      "ADJ     : 2339\n",
      "PRON    : 2313\n",
      "PROPN   : 2310\n",
      "ADV     : 2003\n",
      "AUX     : 1540\n",
      "CCONJ   : 1501\n",
      "SCONJ   : 968\n",
      "PART    : 845\n",
      "NUM     : 451\n",
      "INTJ    : 55\n",
      "X       : 15\n",
      "SYM     : 2\n"
     ]
    }
   ],
   "source": [
    "for key ,value in sorted(POS_counts.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f'{doc.vocab[key].text:{8}}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nouns and punctuation marks are the most common POS tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Visualize dependency parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on their POS tags, we can also visualize the relationship between our words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4ab1881f2620400295e2b169bc764ae6-0\" class=\"displacy\" width=\"800\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: white; background: #09a3d5; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">call</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">our</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">world</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Flatland</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4ab1881f2620400295e2b169bc764ae6-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4ab1881f2620400295e2b169bc764ae6-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4ab1881f2620400295e2b169bc764ae6-0-1\" stroke-width=\"2px\" d=\"M362,227.0 362,177.0 647.0,177.0 647.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4ab1881f2620400295e2b169bc764ae6-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,229.0 L358,221.0 366,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4ab1881f2620400295e2b169bc764ae6-0-2\" stroke-width=\"2px\" d=\"M512,227.0 512,202.0 644.0,202.0 644.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4ab1881f2620400295e2b169bc764ae6-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,229.0 L508,221.0 516,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4ab1881f2620400295e2b169bc764ae6-0-3\" stroke-width=\"2px\" d=\"M212,227.0 212,152.0 650.0,152.0 650.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4ab1881f2620400295e2b169bc764ae6-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M650.0,229.0 L654.0,221.0 646.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# considering only our first 5 tokens\n",
    "\n",
    "displacy.render(list(doc.sents)[11][:5], style='dep', options={'compact': True, 'bg': '#09a3d5', 'color': 'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recoginition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text/origin_of_species.txt', encoding='utf8') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In considering the Origin of Species, it is quite conceivable that a\n",
       "naturalist, reflecting on the mutual affinities of organic beings, on their\n",
       "embryological relations, their geographical distribution, geological\n",
       "succession, and other such facts, might come to the conclusion that each\n",
       "species had not been independently created, but had descended, like\n",
       "varieties, from other species."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[179]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Recognize named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display entity info\n",
    "\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+': '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Origin of Species: WORK_OF_ART - Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(sentences[179])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nevertheless, such a conclusion, even if\n",
       "well founded, would be unsatisfactory, until it could be shown how the\n",
       "innumerable species inhabiting this world have been modified, so as to\n",
       "acquire that perfection of structure and coadaptation which most justly\n",
       "excites our admiration."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "show_ents(sentences[180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Identify sentences with 'n' or more named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sents_n_ents(doc, n=1):\n",
    "    list_sentences = [sentence for sentence in doc.sents if len(sentence.ents) >= n]\n",
    "    return list_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences with 4 or more named entities\n",
    "\n",
    "ner_sentences = sents_n_ents(doc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 264 sentences with 4 or more named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Recognize named entities in one of these sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Pigeons were much valued by Akber Khan\n",
       "in India, about the year 1600; never less than 20,000 pigeons were taken\n",
       "with the court."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_sentences[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akber Khan: PERSON - People, including fictional\n",
      "India: GPE - Countries, cities, states\n",
      "about the year 1600: DATE - Absolute or relative dates or periods\n",
      "less than 20,000: CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "show_ents(ner_sentences[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Visualize named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot; Pigeons were much valued by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akber Khan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</br>in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about the year 1600\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "; never \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    less than 20,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " pigeons were taken\n",
       "with the court. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(ner_sentences[14], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Add a named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "if that\n",
       "between America and Europe is ample, will that between the Continent and\n",
       "the Azores, or Madeira, or the Canaries, or Ireland, be sufficient?"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_sentences[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America: GPE - Countries, cities, states\n",
      "Europe: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Continent: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Canaries: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Ireland: GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(ner_sentences[24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, [Azores](https://en.wikipedia.org/wiki/Azores) and [Madeira](https://en.wikipedia.org/wiki/Madeira) are not recognized as a named entity - LOC - by spaCy. Let's change that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this, we need to know the position - the indices - of our tokens of interest in our `doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_i_madeira = [token.i for token in doc if token.text == 'Madeira']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_i_azores = [token.i for token in doc if token.text == 'Azores']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that for our sentence of interest the token \"Madeira\" is the third token after the token \"Azores\", we can use that information to identify our indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_i=[]\n",
    "\n",
    "for token_i in token_i_azores:\n",
    "    if token_i + 3 in token_i_madeira:\n",
    "        possible_i.append(token_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20728]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, there's only one possibility. Let's see if it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azores, or Madeira, or the Canaries, or Ireland, be sufficient?"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20728:20743]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be our sentence! Let's confirm our indices and add a named entity to these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azores"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20728]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madeira"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "azores_ent = Span(doc, 20728, 20729, label='LOC')\n",
    "madeira_ent = Span(doc, 20731, 20732, label='LOC')\n",
    "\n",
    "doc.ents = list(doc.ents) + [azores_ent, madeira_ent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America: GPE - Countries, cities, states\n",
      "Europe: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Continent: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Azores: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Madeira: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Canaries: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "Ireland: GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(ner_sentences[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">if that</br>between \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Europe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " is ample, will that between the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Continent\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and</br>the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Azores\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madeira\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Canaries\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ireland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", be sufficient? </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(ner_sentences[24], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this means that Azores and Madeira will be identified as entities in this sentence, but not in other occurrences throughout our document. In order to change this, we'll use spaCy's **PhraseMatcher**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Add a named entity to all occurences of a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the matcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create match patterns and add them to the matcher\n",
    "\n",
    "pattern1 = nlp(\"Azores\")\n",
    "pattern2 = nlp(\"Madeira\")\n",
    "\n",
    "matcher.add('PATTERN1', None, pattern1)\n",
    "matcher.add('PATTERN2', None, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN2:  20570 --> 20571  (Madeira)\n",
      "PATTERN1:  20728 --> 20729  (Azores)\n",
      "PATTERN2:  20731 --> 20732  (Madeira)\n",
      "PATTERN2:  21980 --> 21981  (Madeira)\n",
      "PATTERN2:  42782 --> 42783  (Madeira)\n",
      "PATTERN2:  53622 --> 53623  (Madeira)\n",
      "PATTERN2:  53690 --> 53691  (Madeira)\n",
      "PATTERN2:  53731 --> 53732  (Madeira)\n",
      "PATTERN2:  53792 --> 53793  (Madeira)\n",
      "PATTERN2:  53895 --> 53896  (Madeira)\n",
      "PATTERN2:  54434 --> 54435  (Madeira)\n",
      "PATTERN1:  55446 --> 55447  (Azores)\n",
      "PATTERN2:  120501 --> 120502  (Madeira)\n",
      "PATTERN2:  129997 --> 129998  (Madeira)\n",
      "PATTERN1:  138931 --> 138932  (Azores)\n",
      "PATTERN2:  149084 --> 149085  (Madeira)\n",
      "PATTERN2:  149475 --> 149476  (Madeira)\n",
      "PATTERN2:  149517 --> 149518  (Madeira)\n",
      "PATTERN2:  149608 --> 149609  (Madeira)\n",
      "PATTERN2:  149716 --> 149717  (Madeira)\n",
      "PATTERN2:  150302 --> 150303  (Madeira)\n",
      "PATTERN1:  150305 --> 150306  (Azores)\n",
      "PATTERN2:  153942 --> 153943  (Madeira)\n",
      "PATTERN2:  153984 --> 153985  (Madeira)\n",
      "PATTERN1:  187445 --> 187446  (Azores)\n",
      "PATTERN2:  187645 --> 187646  (Madeira)\n",
      "PATTERN2:  187754 --> 187755  (Madeira)\n",
      "PATTERN1:  187916 --> 187917  (Azores)\n",
      "PATTERN2:  190372 --> 190373  (Madeira)\n",
      "PATTERN1:  190384 --> 190385  (Azores)\n",
      "PATTERN2:  190421 --> 190422  (Madeira)\n",
      "PATTERN2:  191242 --> 191243  (Madeira)\n",
      "PATTERN2:  191612 --> 191613  (Madeira)\n",
      "PATTERN2:  191640 --> 191641  (Madeira)\n",
      "PATTERN2:  193779 --> 193780  (Madeira)\n",
      "PATTERN1:  195084 --> 195085  (Azores)\n",
      "PATTERN2:  195260 --> 195261  (Madeira)\n",
      "PATTERN2:  195315 --> 195316  (Madeira)\n",
      "PATTERN2:  195610 --> 195611  (Madeira)\n",
      "PATTERN2:  195632 --> 195633  (Madeira)\n"
     ]
    }
   ],
   "source": [
    "# apply the matcher to our doc\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(doc.vocab.strings[match_id]+': ', str(start)+' --> '+str(end), ' ('+doc[start:end].text+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now identified all the occurences of our tokens \"Azores\" and \"Madeira\". Let's add a named entity to all of them."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# new entities excluding the ones we already added to avoid conflicts\n",
    "\n",
    "\n",
    "new_ents = [Span(doc, start, end, label='LOC') for _, start, end in matcher(doc) \n",
    "            if (start != 20728) and (start != 20731)]\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, several occurrences of the token \"Madeira\" were identified with the named entity \"ORG\". Since we cannot have overlapping entities, let's try to do this only for the \"Azores\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the matcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create match patterns and add them to the matcher\n",
    "\n",
    "pattern = nlp(\"Azores\")\n",
    "\n",
    "matcher.add('PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATTERN:  20728 --> 20729  (Azores)\n",
      "PATTERN:  55446 --> 55447  (Azores)\n",
      "PATTERN:  138931 --> 138932  (Azores)\n",
      "PATTERN:  150305 --> 150306  (Azores)\n",
      "PATTERN:  187445 --> 187446  (Azores)\n",
      "PATTERN:  187916 --> 187917  (Azores)\n",
      "PATTERN:  190384 --> 190385  (Azores)\n",
      "PATTERN:  195084 --> 195085  (Azores)\n"
     ]
    }
   ],
   "source": [
    "# apply the matcher to our doc\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(doc.vocab.strings[match_id]+': ', str(start)+' --> '+str(end), ' ('+doc[start:end].text+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new entities excluding the one we already added to avoid conflicts\n",
    "# there's also other conflicting doc.ents with start=187916 and 190384\n",
    "\n",
    "new_ents = [Span(doc, start, end, label='LOC') for _, start, end in matcher(doc) \n",
    "            if (start != 20728) and (start !=187916) and (start !=190384)]\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if this worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr. Thwaites informs me that he\n",
       "has observed similar facts in Ceylon, and analogous observations have been\n",
       "made by Mr. H. C. Watson on European species of plants brought from the\n",
       "Azores to England."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for pattern with start=55446\n",
    "\n",
    "doc[55411:55450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thwaites: PERSON - People, including fictional\n",
      "Ceylon: GPE - Countries, cities, states\n",
      "H. C. Watson: PERSON - People, including fictional\n",
      "European: NORP - Nationalities or religious or political groups\n",
      "Azores: LOC - Non-GPE locations, mountain ranges, bodies of water\n",
      "England: GPE - Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc[55411:55450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thwaites\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " informs me that he</br>has observed similar facts in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ceylon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and analogous observations have been</br>made by Mr. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    H. C. Watson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " species of plants brought from the</br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Azores\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc[55411:55450], style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the \"Azores\" token is now identified as a LOC - Non-GPE locations, mountain ranges, bodies of water."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
