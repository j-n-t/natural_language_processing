{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to **assign over 400 000 quora questions to different categories**, or topics.\n",
    "\n",
    "For that, we'll be using two different methods:\n",
    "* **Latent Dirichlet Allocation (LDA)**\n",
    "* **Non-Negative Matrix Factorization (NMF)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora = pd.read_csv(\"data/quora_questions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the isspace() method\n",
    "\n",
    "empty_strings = []\n",
    "\n",
    "for i, q in quora.itertuples():\n",
    "    if q.isspace():\n",
    "        empty_strings.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(empty_strings)\n",
    "print(len(empty_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no questions that correspond to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404289"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length\n",
    "\n",
    "len(quora)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 404 289 quora questions. Our dataset is cleaned and we can now perform topic modeling with LDA and NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Create a vectorized document term matrix with `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(quora['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<404289x38669 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2002912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a sparse matrix for the 404 289 questions for a total of 38 669 different words. Let's try to  group these questions into 20 different topics with the LDA method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create an instance of LDA with 20 expected components and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=20, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Check how we can have access to words and topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38669\n"
     ]
    }
   ],
   "source": [
    "# words\n",
    "\n",
    "print(len(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schooled\n",
      "backup\n",
      "shitty\n",
      "shepherds\n",
      "azealia\n",
      "curly\n",
      "intervening\n",
      "arsenal\n",
      "15days\n",
      "darkseid\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_word_id = random.randint(0,38668)\n",
    "    print(cv.get_feature_names()[random_word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we have seen before, we have a total of 38 669 different words. We've print out 10 random words of those 38 669 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics\n",
    "\n",
    "len(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38669"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LDA.components_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have 20 different topics. And for each topic, we have a certain combination of our total of 38 669 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media\n",
      "google\n",
      "good\n",
      "company\n",
      "india\n",
      "social\n",
      "career\n",
      "history\n",
      "service\n",
      "best\n"
     ]
    }
   ],
   "source": [
    "# top 10 words for topic #0\n",
    "\n",
    "top10_word_indices = LDA.components_[0].argsort()[-10:]\n",
    "\n",
    "for index in top10_word_indices:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the top 10 words for topic #0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Print out the top 15 words for each of the 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 15 WORDS FOR TOPIC #0\n",
      "['sydney', 'development', 'code', 'open', 'services', 'media', 'google', 'good', 'company', 'india', 'social', 'career', 'history', 'service', 'best']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #1\n",
      "['economy', 'process', 'making', 'government', 'rupee', 'india', 'word', 'money', 'rs', 'english', 'black', 'indian', '1000', 'notes', '500']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #2\n",
      "['current', 'ones', 'alcohol', 'center', 'legal', 'home', 'state', 'compare', 'man', 'purpose', 'good', 'india', 'cost', 'average', 'does']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #3\n",
      "['answers', 'year', 'facts', 'apple', 'mind', 'series', 'looking', 'interesting', 'worth', 'big', 'exist', 'tv', 'does', 'iphone', 'new']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #4\n",
      "['australia', 'overcome', 'usa', 'students', 'student', 'visa', 'canada', 'mba', 'apply', 'jobs', 'college', 'differences', 'india', 'car', 'job']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #5\n",
      "['different', 'russia', 'win', 'relationship', 'culture', 'countries', 'pakistan', 'china', 'like', 'math', 'india', 'war', 'does', 'long', 'world']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #6\n",
      "['lose', 'visit', 'places', 'place', 'meaning', 'write', 'weight', 'good', 'study', 'university', 'days', 'learning', 'live', 'start', 'best']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #7\n",
      "['earn', '2016', 'english', 'president', 'hillary', 'clinton', 'ways', 'business', 'money', 'improve', 'india', 'donald', 'online', 'trump', 'best']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #8\n",
      "['drive', 'create', 'snapchat', 'download', 'whatsapp', 'effects', 'internet', 'using', 'mobile', 'app', 'android', 'data', 'phone', 'free', 'use']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #9\n",
      "['industry', 'makes', 'stock', 'wrong', 'child', 'family', 'fall', 'india', 'deal', 'height', 'age', 'market', 'youtube', 'increase', 'important']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #10\n",
      "['universe', 'best', 'employees', 'new', 'windows', 'learn', 'energy', 'science', 'computer', 'going', 'programming', 'day', 'language', 'things', 'know']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #11\n",
      "['god', 'like', 'working', 'software', 'believe', 'country', 'google', 'mechanical', 'questions', 'engineer', 'ask', 'quora', 'engineering', 'difference', 'people']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #12\n",
      "['gmail', 'change', 'books', 'years', 'facebook', 'password', 'thing', 'read', 'number', 'school', 'movie', 'year', 'old', 'account', 'life']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #13\n",
      "['friends', 'kill', 'credit', 'battle', 'happened', 'hotel', 'police', 'game', 'safe', 'money', 'tell', 'instagram', 'card', 'make', 'did']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #14\n",
      "['indians', 'review', 'matter', 'does', 'indian', 'air', 'space', 'speed', 'light', 'chinese', 'human', 'american', 'com', 'earth', 'think']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #15\n",
      "['watch', 'site', 'asked', 'buy', 'like', 'answer', 'girl', 'girls', 'happens', 'website', 'questions', 'movies', 'question', 'best', 'quora']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #16\n",
      "['months', 'gate', 'preparation', 'jee', 'iit', 'good', '2016', 'cat', '2017', 'united', 'states', 'lose', 'exam', 'weight', 'prepare']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #17\n",
      "['past', 'future', 'daily', 'main', 'humans', 'die', 'biggest', 'law', 'living', 'parents', 'life', 'travel', 'water', 'possible', 'time']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #18\n",
      "['reduce', 'good', 'fat', 'eat', 'self', 'sex', 'rid', 'laptop', 'hair', 'men', 'women', 'book', 'learn', 'way', 'best']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #19\n",
      "['time', 'look', 'girl', 'guy', 'sex', 'favorite', 'good', 'person', 'stop', 'love', 'feel', 'mean', 'work', 'like', 'does']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Create a dataframe with each question and the correspoding topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404289, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00714286, 0.00714286, 0.00714286, 0.00714286, 0.00714286,\n",
       "       0.00714286, 0.00714286, 0.00714286, 0.72140237, 0.1500262 ,\n",
       "       0.00714286, 0.00714286, 0.00714286, 0.00714286, 0.00714286,\n",
       "       0.00714286, 0.00714286, 0.00714286, 0.00714286, 0.00714286])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for question #2\n",
    "\n",
    "topic_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.72, 0.15, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[2].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[2].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this, question #2 belongs to topic #8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all questions\n",
    "\n",
    "quora_lda = quora.copy()\n",
    "quora_lda['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Topic\n",
       "0  What is the step by step guide to invest in sh...     16\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...     17\n",
       "2  How can I increase the speed of my internet co...      8\n",
       "3  Why am I mentally very lonely? How can I solve...     19\n",
       "4  Which one dissolve in water quikly sugar, salt...     17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_lda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've managed to assign each question to one of the 20 topics. Let's do the same thing with the NMF method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Create a vectorized document term matrix with `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(quora['Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<404289x38669 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2002912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now used `TfidfVectorizer` instead of `CountVectorizer` to create our document term matrix. Let's try to group these questions into 20 different topics with the NMF method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Create an instance of NMF with 20 expected components and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=20, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Print out the top 15 words for each of the 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 15 WORDS FOR TOPIC #0\n",
      "['thing', 'read', 'place', 'visit', 'places', 'phone', 'buy', 'laptop', 'movie', 'ways', '2016', 'books', 'book', 'movies', 'best']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #1\n",
      "['majors', 'recruit', 'sex', 'looking', 'differ', 'use', 'exist', 'really', 'compare', 'cost', 'long', 'feel', 'work', 'mean', 'does']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #2\n",
      "['add', 'answered', 'needing', 'post', 'easily', 'improvement', 'delete', 'asked', 'google', 'answers', 'answer', 'ask', 'question', 'questions', 'quora']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #3\n",
      "['using', 'website', 'investment', 'friends', 'black', 'internet', 'free', 'home', 'easy', 'youtube', 'ways', 'earn', 'online', 'make', 'money']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #4\n",
      "['balance', 'earth', 'day', 'death', 'changed', 'live', 'want', 'change', 'moment', 'real', 'important', 'thing', 'meaning', 'purpose', 'life']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #5\n",
      "['reservation', 'engineering', 'minister', 'president', 'company', 'china', 'business', 'country', 'olympics', 'available', 'job', 'spotify', 'war', 'pakistan', 'india']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #6\n",
      "['beginners', 'online', 'english', 'book', 'did', 'hacking', 'want', 'python', 'languages', 'java', 'learning', 'start', 'language', 'programming', 'learn']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #7\n",
      "['happen', 'presidency', 'think', 'presidential', '2016', 'vote', 'better', 'election', 'did', 'win', 'hillary', 'president', 'clinton', 'donald', 'trump']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #8\n",
      "['russia', 'business', 'win', 'coming', 'countries', 'place', 'pakistan', 'happen', 'end', 'country', 'iii', 'start', 'did', 'war', 'world']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #9\n",
      "['indian', 'companies', 'don', 'guy', 'men', 'culture', 'women', 'work', 'girls', 'live', 'girl', 'look', 'sex', 'feel', 'like']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #10\n",
      "['ca', 'departments', 'positions', 'movies', 'songs', 'business', 'read', 'start', 'job', 'work', 'engineering', 'ways', 'bad', 'books', 'good']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #11\n",
      "['money', 'modi', 'currency', 'economy', 'think', 'government', 'ban', 'banning', 'black', 'indian', 'rupee', 'rs', '1000', 'notes', '500']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #12\n",
      "['blowing', 'resolutions', 'resolution', 'mind', 'likes', 'girl', '2017', 'year', 'don', 'employees', 'going', 'day', 'things', 'new', 'know']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #13\n",
      "['aspects', 'fluent', 'skill', 'spoken', 'ways', 'language', 'fluently', 'speak', 'communication', 'pronunciation', 'speaking', 'writing', 'skills', 'improve', 'english']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #14\n",
      "['diet', 'help', 'healthy', 'exercise', 'month', 'pounds', 'reduce', 'quickly', 'loss', 'fast', 'fat', 'ways', 'gain', 'lose', 'weight']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #15\n",
      "['having', 'feel', 'long', 'spend', 'did', 'person', 'machine', 'movies', 'favorite', 'job', 'home', 'sex', 'possible', 'travel', 'time']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #16\n",
      "['marriage', 'make', 'did', 'girlfriend', 'feel', 'tell', 'forget', 'really', 'friend', 'true', 'know', 'person', 'girl', 'fall', 'love']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #17\n",
      "['easy', 'hack', 'prepare', 'quickest', 'facebook', 'increase', 'painless', 'instagram', 'account', 'best', 'commit', 'fastest', 'suicide', 'easiest', 'way']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #18\n",
      "['web', 'java', 'scripting', 'phone', 'mechanical', 'better', 'job', 'use', 'account', 'data', 'software', 'science', 'computer', 'engineering', 'difference']\n",
      "\n",
      "\n",
      "TOP 15 WORDS FOR TOPIC #19\n",
      "['earth', 'blowing', 'stop', 'use', 'easily', 'mind', 'google', 'flat', 'questions', 'hate', 'believe', 'ask', 'don', 'think', 'people']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Create a dataframe with each question and the correspoding topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = nmf_model.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_nmf = quora.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_nmf['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Topic\n",
       "0  What is the step by step guide to invest in sh...      5\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...     16\n",
       "2  How can I increase the speed of my internet co...     17\n",
       "3  Why am I mentally very lonely? How can I solve...     11\n",
       "4  Which one dissolve in water quikly sugar, salt...     14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_nmf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
