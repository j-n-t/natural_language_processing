{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to build a **deep learning model capable of answering some simple questions**.\n",
    "\n",
    "This work is based on the *bAbI project*, https://research.fb.com/downloads/babi/, and on the papers *Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks*, https://arxiv.org/pdf/1502.05698.pdf, and *End-To-End Memory Networks*, https://arxiv.org/pdf/1503.08895.pdf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train_qa.txt\", \"rb\") as fp:\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/test_qa.txt\", \"rb\") as fp:\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# story\n",
    "\n",
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question\n",
    "\n",
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "\n",
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create vocabulary with all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "all_data = test_data + train_data\n",
    "\n",
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'yes'/'no' answers to the vocabulary\n",
    "\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Set vocabulary length, max story length and max question length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 extra space for Keras's pad_sequences (0)\n",
    "\n",
    "vocab_len = len(vocab) + 1\n",
    "\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max story length\n",
    "\n",
    "max_story_len = max([len(data[0]) for data in all_data])\n",
    "\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max question length\n",
    "\n",
    "max_question_len = max([len(data[1]) for data in all_data])\n",
    "\n",
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'office': 1,\n",
       " 'in': 2,\n",
       " '?': 3,\n",
       " 'discarded': 4,\n",
       " 'dropped': 5,\n",
       " 'milk': 6,\n",
       " 'no': 7,\n",
       " '.': 8,\n",
       " 'bathroom': 9,\n",
       " 'went': 10,\n",
       " 'took': 11,\n",
       " 'mary': 12,\n",
       " 'hallway': 13,\n",
       " 'there': 14,\n",
       " 'john': 15,\n",
       " 'back': 16,\n",
       " 'up': 17,\n",
       " 'yes': 18,\n",
       " 'moved': 19,\n",
       " 'put': 20,\n",
       " 'sandra': 21,\n",
       " 'left': 22,\n",
       " 'apple': 23,\n",
       " 'journeyed': 24,\n",
       " 'picked': 25,\n",
       " 'grabbed': 26,\n",
       " 'football': 27,\n",
       " 'got': 28,\n",
       " 'down': 29,\n",
       " 'kitchen': 30,\n",
       " 'travelled': 31,\n",
       " 'is': 32,\n",
       " 'garden': 33,\n",
       " 'daniel': 34,\n",
       " 'the': 35,\n",
       " 'to': 36,\n",
       " 'bedroom': 37}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUESTIONS\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWERS\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        \n",
    "        # word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # word index for every word in question\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        # word index for 'Yes'/'No' answers\n",
    "        # index 0 is reserved so we're going to use + 1 for the length of y\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        # y = 1 for index corresponding to the word_index of the answer ('Yes' or 'No')\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # append each set of story, question and answer to their respective lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # pad the sequences based on their max length\n",
    "    # (so that the RNN can be trained on uniformly long sequences)\n",
    "    X_pad = pad_sequences(X, maxlen=max_story_len)\n",
    "    Xq_pad = pad_sequences(Xq, maxlen=max_question_len)\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "        \n",
    "    return (X_pad, Xq_pad, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_train, questions_train, answers_train = vectorize_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_test, questions_test, answers_test = vectorize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 35, 37,  8],\n",
       "       [ 0,  0,  0, ..., 35, 13,  8],\n",
       "       [ 0,  0,  0, ..., 35,  9,  8],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 35, 37,  8],\n",
       "       [ 0,  0,  0, ...,  6, 14,  8],\n",
       "       [ 0,  0,  0, ..., 23, 14,  8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 35, 37,  8],\n",
       "       [ 0,  0,  0, ..., 35, 33,  8],\n",
       "       [ 0,  0,  0, ..., 35, 33,  8],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 35, 23,  8],\n",
       "       [ 0,  0,  0, ..., 35, 33,  8],\n",
       "       [ 0,  0,  0, ..., 23, 14,  8]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 156 156\n"
     ]
    }
   ],
   "source": [
    "# for 3 random stories\n",
    "\n",
    "print(len(stories_train[214]), len(stories_train[2341]), len(stories_train[5679]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32, 21,  2, 35, 13,  3],\n",
       "       [32, 34,  2, 35,  9,  3],\n",
       "       [32, 34,  2, 35,  1,  3],\n",
       "       ...,\n",
       "       [32, 21,  2, 35, 13,  3],\n",
       "       [32, 12,  2, 35, 30,  3],\n",
       "       [32, 12,  2, 35, 37,  3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32, 15,  2, 35, 30,  3],\n",
       "       [32, 15,  2, 35, 30,  3],\n",
       "       [32, 15,  2, 35, 33,  3],\n",
       "       ...,\n",
       "       [32, 12,  2, 35, 37,  3],\n",
       "       [32, 21,  2, 35, 33,  3],\n",
       "       [32, 12,  2, 35, 33,  3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 6\n"
     ]
    }
   ],
   "source": [
    "# for 3 random questions\n",
    "\n",
    "print(len(questions_train[256]), len(questions_train[2356]), len(questions_train[7409]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the stories and questions are now vectorized and padded (even though all the questions seem  to have the same length by default, we've padded them just to be safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, only two values of the vectorized answers are not zero. We have 497 positive answers (index 18) and 503 negative answers (index 7) for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two inputs, stories and questions and so we need to use placeholders. `Input()` is used to instantiate a Keras tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\joaon\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\joaon\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Input Encoder m\n",
    "\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Encoder c\n",
    "\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Encoder\n",
    "\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the sequences\n",
    "\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dot product to compute the match between first input vector sequence and the question\n",
    "\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "\n",
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2, 1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce with RNN (LSTM)\n",
    "\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization with Dropout\n",
    "\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_len)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the final model\n",
    "\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\joaon\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\joaon\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.9028 - acc: 0.4887 - val_loss: 0.7007 - val_acc: 0.4970\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 9s 884us/step - loss: 0.7035 - acc: 0.4932 - val_loss: 0.6934 - val_acc: 0.5030\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.6958 - acc: 0.5023 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 9s 890us/step - loss: 0.6950 - acc: 0.4988 - val_loss: 0.6934 - val_acc: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 9s 882us/step - loss: 0.6950 - acc: 0.4927 - val_loss: 0.6937 - val_acc: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 9s 890us/step - loss: 0.6943 - acc: 0.5034 - val_loss: 0.6939 - val_acc: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 9s 883us/step - loss: 0.6947 - acc: 0.4975 - val_loss: 0.6945 - val_acc: 0.4970\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 9s 927us/step - loss: 0.6948 - acc: 0.4950 - val_loss: 0.6946 - val_acc: 0.4970\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 9s 887us/step - loss: 0.6940 - acc: 0.5024 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 9s 886us/step - loss: 0.6937 - acc: 0.5074 - val_loss: 0.6957 - val_acc: 0.4920\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 9s 889us/step - loss: 0.6914 - acc: 0.5244 - val_loss: 0.6931 - val_acc: 0.5280\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 9s 889us/step - loss: 0.6797 - acc: 0.5650 - val_loss: 0.6660 - val_acc: 0.6140\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 9s 875us/step - loss: 0.6449 - acc: 0.6313 - val_loss: 0.6367 - val_acc: 0.6430\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 9s 878us/step - loss: 0.6307 - acc: 0.6485 - val_loss: 0.6266 - val_acc: 0.6570\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 9s 915us/step - loss: 0.6217 - acc: 0.6688 - val_loss: 0.6209 - val_acc: 0.6540\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 9s 908us/step - loss: 0.6143 - acc: 0.6670 - val_loss: 0.6225 - val_acc: 0.6450\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 9s 892us/step - loss: 0.6087 - acc: 0.6785 - val_loss: 0.6048 - val_acc: 0.6600\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 9s 884us/step - loss: 0.6019 - acc: 0.6791 - val_loss: 0.6054 - val_acc: 0.6580\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 9s 895us/step - loss: 0.5971 - acc: 0.6831 - val_loss: 0.6126 - val_acc: 0.6590\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.5928 - acc: 0.6889 - val_loss: 0.5969 - val_acc: 0.6640\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 9s 874us/step - loss: 0.5849 - acc: 0.6887 - val_loss: 0.5871 - val_acc: 0.6670\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 9s 882us/step - loss: 0.5774 - acc: 0.7015 - val_loss: 0.6021 - val_acc: 0.6660\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 9s 920us/step - loss: 0.5737 - acc: 0.7027 - val_loss: 0.5777 - val_acc: 0.6840\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 9s 883us/step - loss: 0.5680 - acc: 0.7102 - val_loss: 0.5711 - val_acc: 0.6930\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 9s 881us/step - loss: 0.5531 - acc: 0.7224 - val_loss: 0.5657 - val_acc: 0.6880\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 9s 908us/step - loss: 0.5425 - acc: 0.7287 - val_loss: 0.5501 - val_acc: 0.6970\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 9s 899us/step - loss: 0.5335 - acc: 0.7305 - val_loss: 0.5597 - val_acc: 0.6870\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 9s 884us/step - loss: 0.5175 - acc: 0.7428 - val_loss: 0.5240 - val_acc: 0.7210\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 9s 886us/step - loss: 0.5028 - acc: 0.7533 - val_loss: 0.5137 - val_acc: 0.7270\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 9s 921us/step - loss: 0.4906 - acc: 0.7626 - val_loss: 0.5131 - val_acc: 0.7260\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 9s 854us/step - loss: 0.4841 - acc: 0.7673 - val_loss: 0.4950 - val_acc: 0.7500\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 8s 809us/step - loss: 0.4717 - acc: 0.7775 - val_loss: 0.4902 - val_acc: 0.7590\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 8s 811us/step - loss: 0.4599 - acc: 0.7831 - val_loss: 0.4858 - val_acc: 0.7620\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 8s 843us/step - loss: 0.4492 - acc: 0.7927 - val_loss: 0.4661 - val_acc: 0.7760\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 8s 831us/step - loss: 0.4411 - acc: 0.7989 - val_loss: 0.4525 - val_acc: 0.7850\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 8s 795us/step - loss: 0.4344 - acc: 0.7984 - val_loss: 0.4459 - val_acc: 0.7760\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 8s 833us/step - loss: 0.4262 - acc: 0.8054 - val_loss: 0.4421 - val_acc: 0.7870\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.4206 - acc: 0.8099 - val_loss: 0.4523 - val_acc: 0.7840\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 8s 831us/step - loss: 0.4198 - acc: 0.8113 - val_loss: 0.4637 - val_acc: 0.7760\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 8s 846us/step - loss: 0.4099 - acc: 0.8143 - val_loss: 0.4416 - val_acc: 0.7980\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 9s 873us/step - loss: 0.4049 - acc: 0.8155 - val_loss: 0.4461 - val_acc: 0.7860\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 8s 847us/step - loss: 0.4039 - acc: 0.8161 - val_loss: 0.4377 - val_acc: 0.7850\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 8s 817us/step - loss: 0.3998 - acc: 0.8146 - val_loss: 0.4225 - val_acc: 0.7950\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 8s 831us/step - loss: 0.4007 - acc: 0.8171 - val_loss: 0.4311 - val_acc: 0.7890\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 8s 822us/step - loss: 0.3900 - acc: 0.8227 - val_loss: 0.4395 - val_acc: 0.7860 0s - loss: 0.3912 - acc\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 9s 883us/step - loss: 0.3978 - acc: 0.8205 - val_loss: 0.4469 - val_acc: 0.7800\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 8s 834us/step - loss: 0.3837 - acc: 0.8216 - val_loss: 0.4322 - val_acc: 0.7870\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 8s 841us/step - loss: 0.3900 - acc: 0.8205 - val_loss: 0.4263 - val_acc: 0.8030\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 8s 832us/step - loss: 0.3881 - acc: 0.8248 - val_loss: 0.4213 - val_acc: 0.8020\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.3801 - acc: 0.8271 - val_loss: 0.4328 - val_acc: 0.7980\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 8s 838us/step - loss: 0.3757 - acc: 0.8277 - val_loss: 0.4275 - val_acc: 0.7990\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 8s 831us/step - loss: 0.3708 - acc: 0.8322 - val_loss: 0.4315 - val_acc: 0.8010\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 8s 838us/step - loss: 0.3653 - acc: 0.8333 - val_loss: 0.4274 - val_acc: 0.7960\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.3643 - acc: 0.8349 - val_loss: 0.4261 - val_acc: 0.7950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 8s 839us/step - loss: 0.3588 - acc: 0.8370 - val_loss: 0.4357 - val_acc: 0.7990\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 8s 849us/step - loss: 0.3609 - acc: 0.8335 - val_loss: 0.4294 - val_acc: 0.7910\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 8s 845us/step - loss: 0.3583 - acc: 0.8405 - val_loss: 0.4587 - val_acc: 0.7800\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.3525 - acc: 0.8391 - val_loss: 0.4492 - val_acc: 0.7950\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 9s 864us/step - loss: 0.3569 - acc: 0.8401 - val_loss: 0.4436 - val_acc: 0.7880\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 8s 845us/step - loss: 0.3525 - acc: 0.8426 - val_loss: 0.4524 - val_acc: 0.7860\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 9s 861us/step - loss: 0.3532 - acc: 0.8376 - val_loss: 0.4540 - val_acc: 0.7940\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.3466 - acc: 0.8429 - val_loss: 0.4423 - val_acc: 0.7960\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 8s 839us/step - loss: 0.3422 - acc: 0.8452 - val_loss: 0.4362 - val_acc: 0.8030\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 8s 826us/step - loss: 0.3379 - acc: 0.8475 - val_loss: 0.4578 - val_acc: 0.7960\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 9s 851us/step - loss: 0.3363 - acc: 0.8470 - val_loss: 0.4687 - val_acc: 0.8000\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 8s 840us/step - loss: 0.3343 - acc: 0.8480 - val_loss: 0.4488 - val_acc: 0.8010\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 8s 836us/step - loss: 0.3401 - acc: 0.8431 - val_loss: 0.4528 - val_acc: 0.7990\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 8s 836us/step - loss: 0.3318 - acc: 0.8500 - val_loss: 0.4643 - val_acc: 0.7970\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 9s 923us/step - loss: 0.3267 - acc: 0.8527 - val_loss: 0.4842 - val_acc: 0.7890\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 9s 870us/step - loss: 0.3348 - acc: 0.8450 - val_loss: 0.4610 - val_acc: 0.7980\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 8s 841us/step - loss: 0.3296 - acc: 0.8501 - val_loss: 0.4788 - val_acc: 0.8050\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 9s 850us/step - loss: 0.3238 - acc: 0.8541 - val_loss: 0.4875 - val_acc: 0.7910\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 8s 801us/step - loss: 0.3232 - acc: 0.8564 - val_loss: 0.4827 - val_acc: 0.7850\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 8s 843us/step - loss: 0.3258 - acc: 0.8551 - val_loss: 0.5115 - val_acc: 0.7970\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 9s 866us/step - loss: 0.3146 - acc: 0.8567 - val_loss: 0.4853 - val_acc: 0.8080\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 9s 852us/step - loss: 0.3103 - acc: 0.8615 - val_loss: 0.4939 - val_acc: 0.8090\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 9s 871us/step - loss: 0.3114 - acc: 0.8631 - val_loss: 0.4980 - val_acc: 0.8140\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 8s 818us/step - loss: 0.3154 - acc: 0.8576 - val_loss: 0.4857 - val_acc: 0.7970\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 8s 842us/step - loss: 0.3079 - acc: 0.8615 - val_loss: 0.5032 - val_acc: 0.8030\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 8s 761us/step - loss: 0.3052 - acc: 0.8628 - val_loss: 0.5157 - val_acc: 0.8010\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 8s 802us/step - loss: 0.3010 - acc: 0.8669 - val_loss: 0.5011 - val_acc: 0.8090\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 8s 797us/step - loss: 0.3007 - acc: 0.8649 - val_loss: 0.4943 - val_acc: 0.8040\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 8s 802us/step - loss: 0.3028 - acc: 0.8676 - val_loss: 0.4999 - val_acc: 0.8010\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 8s 775us/step - loss: 0.2989 - acc: 0.8656 - val_loss: 0.4822 - val_acc: 0.8120\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 9s 854us/step - loss: 0.2986 - acc: 0.8689 - val_loss: 0.5024 - val_acc: 0.8000\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 8s 793us/step - loss: 0.2976 - acc: 0.8707 - val_loss: 0.4830 - val_acc: 0.8140\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 8s 782us/step - loss: 0.2949 - acc: 0.8676 - val_loss: 0.4916 - val_acc: 0.8090\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 8s 806us/step - loss: 0.2902 - acc: 0.8688 - val_loss: 0.4882 - val_acc: 0.8100\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 8s 833us/step - loss: 0.2948 - acc: 0.8682 - val_loss: 0.4849 - val_acc: 0.7990\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 9s 853us/step - loss: 0.2863 - acc: 0.8757 - val_loss: 0.4963 - val_acc: 0.8000\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 8s 837us/step - loss: 0.2786 - acc: 0.8756 - val_loss: 0.4995 - val_acc: 0.8050\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 8s 836us/step - loss: 0.2932 - acc: 0.8752 - val_loss: 0.5040 - val_acc: 0.8000\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 9s 882us/step - loss: 0.2796 - acc: 0.8775 - val_loss: 0.5437 - val_acc: 0.8020\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 8s 842us/step - loss: 0.2862 - acc: 0.8750 - val_loss: 0.5275 - val_acc: 0.8030\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 8s 841us/step - loss: 0.2787 - acc: 0.8789 - val_loss: 0.5441 - val_acc: 0.8040\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 8s 836us/step - loss: 0.2767 - acc: 0.8817 - val_loss: 0.5229 - val_acc: 0.8050\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 8s 849us/step - loss: 0.2778 - acc: 0.8799 - val_loss: 0.4956 - val_acc: 0.8160\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 8s 848us/step - loss: 0.2720 - acc: 0.8808 - val_loss: 0.5015 - val_acc: 0.8090\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 8s 827us/step - loss: 0.2718 - acc: 0.8806 - val_loss: 0.5252 - val_acc: 0.8040\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 8s 810us/step - loss: 0.2716 - acc: 0.8808 - val_loss: 0.5382 - val_acc: 0.8060\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 9s 864us/step - loss: 0.2783 - acc: 0.8808 - val_loss: 0.5056 - val_acc: 0.8170\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 8s 795us/step - loss: 0.2661 - acc: 0.8873 - val_loss: 0.5525 - val_acc: 0.8070\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 8s 782us/step - loss: 0.2629 - acc: 0.8828 - val_loss: 0.5501 - val_acc: 0.8140\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 8s 799us/step - loss: 0.2602 - acc: 0.8896 - val_loss: 0.5696 - val_acc: 0.8010\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 9s 852us/step - loss: 0.2651 - acc: 0.8860 - val_loss: 0.5144 - val_acc: 0.8250\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 8s 833us/step - loss: 0.2663 - acc: 0.8853 - val_loss: 0.5575 - val_acc: 0.8130\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 8s 811us/step - loss: 0.2628 - acc: 0.8873 - val_loss: 0.5350 - val_acc: 0.8030\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 8s 812us/step - loss: 0.2585 - acc: 0.8895 - val_loss: 0.5212 - val_acc: 0.8200\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.2608 - acc: 0.8875 - val_loss: 0.5414 - val_acc: 0.8090\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 8s 822us/step - loss: 0.2641 - acc: 0.8900 - val_loss: 0.5529 - val_acc: 0.8090\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 8s 804us/step - loss: 0.2515 - acc: 0.8946 - val_loss: 0.5575 - val_acc: 0.8210\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 8s 818us/step - loss: 0.2522 - acc: 0.8937 - val_loss: 0.5263 - val_acc: 0.8150\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.2597 - acc: 0.8893 - val_loss: 0.5748 - val_acc: 0.8060\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.2458 - acc: 0.896 - 9s 869us/step - loss: 0.2457 - acc: 0.8960 - val_loss: 0.5635 - val_acc: 0.8170\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 9s 866us/step - loss: 0.2539 - acc: 0.8916 - val_loss: 0.5792 - val_acc: 0.8180\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 9s 885us/step - loss: 0.2427 - acc: 0.8992 - val_loss: 0.5794 - val_acc: 0.8190\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 9s 899us/step - loss: 0.2496 - acc: 0.8942 - val_loss: 0.5730 - val_acc: 0.8130\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 9s 865us/step - loss: 0.2528 - acc: 0.8936 - val_loss: 0.5686 - val_acc: 0.8130\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 9s 865us/step - loss: 0.2507 - acc: 0.8923 - val_loss: 0.5817 - val_acc: 0.8200\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 9s 854us/step - loss: 0.2433 - acc: 0.8991 - val_loss: 0.5693 - val_acc: 0.8140\n"
     ]
    }
   ],
   "source": [
    "qa = model.fit([stories_train, questions_train], answers_train, batch_size=32, epochs=120, validation_data=([stories_test, questions_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'qa_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(qa.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(qa.history['acc'])\n",
    "plt.plot(qa.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Evaluate and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(([stories_test, questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.46382896e-14, 1.70085266e-14, 1.58988694e-14, ...,\n",
       "        1.42198299e-14, 1.59783956e-14, 1.58654861e-14],\n",
       "       [3.63212742e-13, 3.93054838e-13, 3.59840819e-13, ...,\n",
       "        3.40538416e-13, 3.89172744e-13, 3.55816125e-13],\n",
       "       [1.70315049e-14, 1.97693695e-14, 1.81275232e-14, ...,\n",
       "        1.74386550e-14, 1.91940139e-14, 1.90443178e-14],\n",
       "       ...,\n",
       "       [8.63874080e-17, 1.10968496e-16, 9.37790807e-17, ...,\n",
       "        9.18978999e-17, 1.13373176e-16, 1.10015921e-16],\n",
       "       [2.80486702e-16, 3.27027721e-16, 3.25891982e-16, ...,\n",
       "        2.91102036e-16, 3.07913391e-16, 3.22496016e-16],\n",
       "       [1.80679793e-22, 2.20827815e-22, 2.30842764e-22, ...,\n",
       "        1.90054199e-22, 1.79911556e-22, 2.09176087e-22]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "# story #0\n",
    "\n",
    "story = ' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "# question #0\n",
    "\n",
    "question = ' '.join(word for word in test_data[0][1])\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True test answer from data is: no\n"
     ]
    }
   ],
   "source": [
    "# answer #0\n",
    "\n",
    "print(\"True test answer from data is:\", test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.46382896e-14 1.70085266e-14 1.58988694e-14 1.83372909e-14\n",
      " 1.65865653e-14 1.44100243e-14 1.63785408e-14 9.98939335e-01\n",
      " 1.57426206e-14 1.58539902e-14 1.62395579e-14 1.59676722e-14\n",
      " 1.55482367e-14 1.41915161e-14 1.35159125e-14 1.49089369e-14\n",
      " 1.59082715e-14 1.55568985e-14 1.06062007e-03 1.43970021e-14\n",
      " 1.60309930e-14 1.44801705e-14 1.58517540e-14 1.48582064e-14\n",
      " 1.65406612e-14 1.53848068e-14 1.74070234e-14 1.70684525e-14\n",
      " 1.45875065e-14 1.77978749e-14 1.62807440e-14 1.61880668e-14\n",
      " 1.49000956e-14 1.79433511e-14 1.55443217e-14 1.42198299e-14\n",
      " 1.59783956e-14 1.58654861e-14]\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# predictions for answer #0\n",
    "\n",
    "print(predictions[0])\n",
    "print(len(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of prediction being the right answer: 0.99893934\n"
     ]
    }
   ],
   "source": [
    "# generate prediction from model\n",
    "\n",
    "val_max = np.argmax(predictions[0])\n",
    "\n",
    "for key, value in tokenizer.word_index.items():\n",
    "    if value == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of prediction being the right answer:\", predictions[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the predicted answer is 'no'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'office', 'in', '?', 'discarded', 'dropped', 'milk', 'no', '.', 'bathroom', 'went', 'took', 'Mary', 'hallway', 'there', 'John', 'back', 'up', 'yes', 'moved', 'put', 'Sandra', 'left', 'apple', 'journeyed', 'picked', 'grabbed', 'football', 'got', 'down', 'kitchen', 'travelled', 'Is', 'garden', 'Daniel', 'the', 'to', 'bedroom'}\n"
     ]
    }
   ],
   "source": [
    "# test the model on new story and question\n",
    "# we can only use the words in the vocabulary\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'grabbed',\n",
       " 'the',\n",
       " 'apple',\n",
       " 'in',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'office',\n",
       " '.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new story\n",
    "\n",
    "my_story = \"John grabbed the apple in the kitchen . Sandra moved to the office .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new question\n",
    "\n",
    "my_question = \"Is John in the kitchen ?\"\n",
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_data = [(my_story, my_question, my_answer)]\n",
    "\n",
    "my_data = [(my_story.split(), my_question.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize new data\n",
    "\n",
    "my_story, my_question, my_answer = vectorize_data(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict my_answer\n",
    "\n",
    "prediction = model.predict(([my_story, my_question]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of prediction being the right answer: 0.94050664\n"
     ]
    }
   ],
   "source": [
    "# generate prediction from model\n",
    "\n",
    "val_max = np.argmax(prediction[0])\n",
    "\n",
    "for key, value in tokenizer.word_index.items():\n",
    "    if value == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of prediction being the right answer:\", prediction[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly predicted that the correct answer is 'yes'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
