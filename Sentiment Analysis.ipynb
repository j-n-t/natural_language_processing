{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this project consists in performing **sentiment analysis with NLTK's VADER** module, https://www.nltk.org/_modules/nltk/sentiment/vader.html, on a dataset with 10 000 Amazon reviews. VADER stands for <b>V</b>alence <b>A</b>ware <b>D</b>ictionary for s<b>E</b>ntiment <b>R</b>easoning, and is a **rule-based algorithm** composed by Hutto and Gilbert: http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/amazonreviews.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...\n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2   pos  Amazing!: This soundtrack is my favorite music...\n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the isspace() method\n",
    "# returns True if there are only whitespace characters in the string. If not, it returns False. \n",
    "\n",
    "empty_strings = []\n",
    "\n",
    "for i, lb, rv in df.itertuples():\n",
    "    if rv.isspace():\n",
    "        empty_strings.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(empty_strings)\n",
    "print(len(empty_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no reviews that correspond to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of both labels\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10 000 movie reviews (5097 are negative and 4903 are positive). Our dataset is cleaned and we can now analyse it with VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Import `SentimentIntensityAnalyzer` and create an sid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Check the lexicon (vocabulary or all valid tokens) of our sid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$:': -1.5,\n",
       " '%)': -0.4,\n",
       " '%-)': -1.5,\n",
       " '&-:': -0.4,\n",
       " '&:': -0.7,\n",
       " \"( '}{' )\": 1.6,\n",
       " '(%': -0.9,\n",
       " \"('-:\": 2.2,\n",
       " \"(':\": 2.3,\n",
       " '((-:': 2.1,\n",
       " '(*': 1.1,\n",
       " '(-%': -0.7,\n",
       " '(-*': 1.3,\n",
       " '(-:': 1.6,\n",
       " '(-:0': 2.8,\n",
       " '(-:<': -0.4,\n",
       " '(-:o': 1.5,\n",
       " '(-:O': 1.5,\n",
       " '(-:{': -0.1,\n",
       " '(-:|>*': 1.9,\n",
       " '(-;': 1.3,\n",
       " '(-;|': 2.1,\n",
       " '(8': 2.6,\n",
       " '(:': 2.2,\n",
       " '(:0': 2.4,\n",
       " '(:<': -0.2,\n",
       " '(:o': 2.5,\n",
       " '(:O': 2.5,\n",
       " '(;': 1.1,\n",
       " '(;<': 0.3,\n",
       " '(=': 2.2,\n",
       " '(?:': 2.1,\n",
       " '(^:': 1.5,\n",
       " '(^;': 1.5,\n",
       " '(^;0': 2.0,\n",
       " '(^;o': 1.9,\n",
       " '(o:': 1.6,\n",
       " \")':\": -2.0,\n",
       " \")-':\": -2.1,\n",
       " ')-:': -2.1,\n",
       " ')-:<': -2.2,\n",
       " ')-:{': -2.1,\n",
       " '):': -1.8,\n",
       " '):<': -1.9,\n",
       " '):{': -2.3,\n",
       " ');<': -2.6,\n",
       " '*)': 0.6,\n",
       " '*-)': 0.3,\n",
       " '*-:': 2.1,\n",
       " '*-;': 2.4,\n",
       " '*:': 1.9,\n",
       " '*<|:-)': 1.6,\n",
       " '*\\\\0/*': 2.3,\n",
       " '*^:': 1.6,\n",
       " ',-:': 1.2,\n",
       " \"---'-;-{@\": 2.3,\n",
       " '--<--<@': 2.2,\n",
       " '.-:': -1.2,\n",
       " '..###-:': -1.7,\n",
       " '..###:': -1.9,\n",
       " '/-:': -1.3,\n",
       " '/:': -1.3,\n",
       " '/:<': -1.4,\n",
       " '/=': -0.9,\n",
       " '/^:': -1.0,\n",
       " '/o:': -1.4,\n",
       " '0-8': 0.1,\n",
       " '0-|': -1.2,\n",
       " '0:)': 1.9,\n",
       " '0:-)': 1.4,\n",
       " '0:-3': 1.5,\n",
       " '0:03': 1.9,\n",
       " '0;^)': 1.6,\n",
       " '0_o': -0.3,\n",
       " '10q': 2.1,\n",
       " '1337': 2.1,\n",
       " '143': 3.2,\n",
       " '1432': 2.6,\n",
       " '14aa41': 2.4,\n",
       " '182': -2.9,\n",
       " '187': -3.1,\n",
       " '2g2b4g': 2.8,\n",
       " '2g2bt': -0.1,\n",
       " '2qt': 2.1,\n",
       " '3:(': -2.2,\n",
       " '3:)': 0.5,\n",
       " '3:-(': -2.3,\n",
       " '3:-)': -1.4,\n",
       " '4col': -2.2,\n",
       " '4q': -3.1,\n",
       " '5fs': 1.5,\n",
       " '8)': 1.9,\n",
       " '8-d': 1.7,\n",
       " '8-o': -0.3,\n",
       " '86': -1.6,\n",
       " '8d': 2.9,\n",
       " ':###..': -2.4,\n",
       " ':$': -0.2,\n",
       " ':&': -0.6,\n",
       " \":'(\": -2.2,\n",
       " \":')\": 2.3,\n",
       " \":'-(\": -2.4,\n",
       " \":'-)\": 2.7,\n",
       " ':(': -1.9,\n",
       " ':)': 2.0,\n",
       " ':*': 2.5,\n",
       " ':-###..': -2.5,\n",
       " ':-&': -0.5,\n",
       " ':-(': -1.5,\n",
       " ':-)': 1.3,\n",
       " ':-))': 2.8,\n",
       " ':-*': 1.7,\n",
       " ':-,': 1.1,\n",
       " ':-.': -0.9,\n",
       " ':-/': -1.2,\n",
       " ':-<': -1.5,\n",
       " ':-d': 2.3,\n",
       " ':-D': 2.3,\n",
       " ':-o': 0.1,\n",
       " ':-p': 1.5,\n",
       " ':-[': -1.6,\n",
       " ':-\\\\': -0.9,\n",
       " ':-c': -1.3,\n",
       " ':-|': -0.7,\n",
       " ':-||': -2.5,\n",
       " ':-Þ': 0.9,\n",
       " ':/': -1.4,\n",
       " ':3': 2.3,\n",
       " ':<': -2.1,\n",
       " ':>': 2.1,\n",
       " ':?)': 1.3,\n",
       " ':?c': -1.6,\n",
       " ':@': -2.5,\n",
       " ':d': 2.3,\n",
       " ':D': 2.3,\n",
       " ':l': -1.7,\n",
       " ':o': -0.4,\n",
       " ':p': 1.4,\n",
       " ':s': -1.2,\n",
       " ':[': -2.0,\n",
       " ':\\\\': -1.3,\n",
       " ':]': 2.2,\n",
       " ':^)': 2.1,\n",
       " ':^*': 2.6,\n",
       " ':^/': -1.2,\n",
       " ':^\\\\': -1.0,\n",
       " ':^|': -1.0,\n",
       " ':c': -2.1,\n",
       " ':c)': 2.0,\n",
       " ':o)': 2.1,\n",
       " ':o/': -1.4,\n",
       " ':o\\\\': -1.1,\n",
       " ':o|': -0.6,\n",
       " ':{': -1.9,\n",
       " ':|': -0.4,\n",
       " ':}': 2.1,\n",
       " ':Þ': 1.1,\n",
       " ';)': 0.9,\n",
       " ';-)': 1.0,\n",
       " ';-*': 2.2,\n",
       " ';-]': 0.7,\n",
       " ';d': 0.8,\n",
       " ';D': 0.8,\n",
       " ';]': 0.6,\n",
       " ';^)': 1.4,\n",
       " '</3': -3.0,\n",
       " '<3': 1.9,\n",
       " '<:': 2.1,\n",
       " '<:-|': -1.4,\n",
       " '=)': 2.2,\n",
       " '=-3': 2.0,\n",
       " '=-d': 2.4,\n",
       " '=-D': 2.4,\n",
       " '=/': -1.4,\n",
       " '=3': 2.1,\n",
       " '=d': 2.3,\n",
       " '=D': 2.3,\n",
       " '=l': -1.2,\n",
       " '=\\\\': -1.2,\n",
       " '=]': 1.6,\n",
       " '=p': 1.3,\n",
       " '=|': -0.8,\n",
       " '>-:': -2.0,\n",
       " '>.<': -1.3,\n",
       " '>:': -2.1,\n",
       " '>:(': -2.7,\n",
       " '>:)': 0.4,\n",
       " '>:-(': -2.7,\n",
       " '>:-)': -0.4,\n",
       " '>:/': -1.6,\n",
       " '>:o': -1.2,\n",
       " '>:p': 1.0,\n",
       " '>:[': -2.1,\n",
       " '>:\\\\': -1.7,\n",
       " '>;(': -2.9,\n",
       " '>;)': 0.1,\n",
       " '>_>^': 2.1,\n",
       " '@:': -2.1,\n",
       " '@>-->--': 2.1,\n",
       " \"@}-;-'---\": 2.2,\n",
       " 'aas': 2.5,\n",
       " 'aayf': 2.7,\n",
       " 'afu': -2.9,\n",
       " 'alol': 2.8,\n",
       " 'ambw': 2.9,\n",
       " 'aml': 3.4,\n",
       " 'atab': -1.9,\n",
       " 'awol': -1.3,\n",
       " 'ayc': 0.2,\n",
       " 'ayor': -1.2,\n",
       " 'aug-00': 0.3,\n",
       " 'bfd': -2.7,\n",
       " 'bfe': -2.6,\n",
       " 'bff': 2.9,\n",
       " 'bffn': 1.0,\n",
       " 'bl': 2.3,\n",
       " 'bsod': -2.2,\n",
       " 'btd': -2.1,\n",
       " 'btdt': -0.1,\n",
       " 'bz': 0.4,\n",
       " 'b^d': 2.6,\n",
       " 'cwot': -2.3,\n",
       " \"d-':\": -2.5,\n",
       " 'd8': -3.2,\n",
       " 'd:': 1.2,\n",
       " 'd:<': -3.2,\n",
       " 'd;': -2.9,\n",
       " 'd=': 1.5,\n",
       " 'doa': -2.3,\n",
       " 'dx': -3.0,\n",
       " 'ez': 1.5,\n",
       " 'fav': 2.0,\n",
       " 'fcol': -1.8,\n",
       " 'ff': 1.8,\n",
       " 'ffs': -2.8,\n",
       " 'fkm': -2.4,\n",
       " 'foaf': 1.8,\n",
       " 'ftw': 2.0,\n",
       " 'fu': -3.7,\n",
       " 'fubar': -3.0,\n",
       " 'fwb': 2.5,\n",
       " 'fyi': 0.8,\n",
       " 'fysa': 0.4,\n",
       " 'g1': 1.4,\n",
       " 'gg': 1.2,\n",
       " 'gga': 1.7,\n",
       " 'gigo': -0.6,\n",
       " 'gj': 2.0,\n",
       " 'gl': 1.3,\n",
       " 'gla': 2.5,\n",
       " 'gn': 1.2,\n",
       " 'gr8': 2.7,\n",
       " 'grrr': -0.4,\n",
       " 'gt': 1.1,\n",
       " 'h&k': 2.3,\n",
       " 'hagd': 2.2,\n",
       " 'hagn': 2.2,\n",
       " 'hago': 1.2,\n",
       " 'hak': 1.9,\n",
       " 'hand': 2.2,\n",
       " 'hho1/2k': 1.4,\n",
       " 'hhoj': 2.0,\n",
       " 'hhok': 0.9,\n",
       " 'hugz': 2.0,\n",
       " 'hi5': 1.9,\n",
       " 'idk': -0.4,\n",
       " 'ijs': 0.7,\n",
       " 'ilu': 3.4,\n",
       " 'iluaaf': 2.7,\n",
       " 'ily': 3.4,\n",
       " 'ily2': 2.6,\n",
       " 'iou': 0.7,\n",
       " 'iyq': 2.3,\n",
       " 'j/j': 2.0,\n",
       " 'j/k': 1.6,\n",
       " 'j/p': 1.4,\n",
       " 'j/t': -0.2,\n",
       " 'j/w': 1.0,\n",
       " 'j4f': 1.4,\n",
       " 'j4g': 1.7,\n",
       " 'jho': 0.8,\n",
       " 'jhomf': 1.0,\n",
       " 'jj': 1.0,\n",
       " 'jk': 0.9,\n",
       " 'jp': 0.8,\n",
       " 'jt': 0.9,\n",
       " 'jw': 1.6,\n",
       " 'jealz': -1.2,\n",
       " 'k4y': 2.3,\n",
       " 'kfy': 2.3,\n",
       " 'kia': -3.2,\n",
       " 'kk': 1.5,\n",
       " 'kmuf': 2.2,\n",
       " 'l': 2.0,\n",
       " 'l&r': 2.2,\n",
       " 'laoj': 1.3,\n",
       " 'lmao': 2.9,\n",
       " 'lmbao': 1.8,\n",
       " 'lmfao': 2.5,\n",
       " 'lmso': 2.7,\n",
       " 'lol': 1.8,\n",
       " 'lolz': 2.7,\n",
       " 'lts': 1.6,\n",
       " 'ly': 2.6,\n",
       " 'ly4e': 2.7,\n",
       " 'lya': 3.3,\n",
       " 'lyb': 3.0,\n",
       " 'lyl': 3.1,\n",
       " 'lylab': 2.7,\n",
       " 'lylas': 2.6,\n",
       " 'lylb': 1.6,\n",
       " 'm8': 1.4,\n",
       " 'mia': -1.2,\n",
       " 'mml': 2.0,\n",
       " 'mofo': -2.4,\n",
       " 'muah': 2.3,\n",
       " 'mubar': -1.0,\n",
       " 'musm': 0.9,\n",
       " 'mwah': 2.5,\n",
       " 'n1': 1.9,\n",
       " 'nbd': 1.3,\n",
       " 'nbif': -0.5,\n",
       " 'nfc': -2.7,\n",
       " 'nfw': -2.4,\n",
       " 'nh': 2.2,\n",
       " 'nimby': -0.8,\n",
       " 'nimjd': -0.7,\n",
       " 'nimq': -0.2,\n",
       " 'nimy': -1.4,\n",
       " 'nitl': -1.5,\n",
       " 'nme': -2.1,\n",
       " 'noyb': -0.7,\n",
       " 'np': 1.4,\n",
       " 'ntmu': 1.4,\n",
       " 'o-8': -0.5,\n",
       " 'o-:': -0.3,\n",
       " 'o-|': -1.1,\n",
       " 'o.o': -0.8,\n",
       " 'O.o': -0.6,\n",
       " 'o.O': -0.6,\n",
       " 'o:': -0.2,\n",
       " 'o:)': 1.5,\n",
       " 'o:-)': 2.0,\n",
       " 'o:-3': 2.2,\n",
       " 'o:3': 2.3,\n",
       " 'o:<': -0.3,\n",
       " 'o;^)': 1.6,\n",
       " 'ok': 1.2,\n",
       " 'o_o': -0.5,\n",
       " 'O_o': -0.5,\n",
       " 'o_O': -0.5,\n",
       " 'pita': -2.4,\n",
       " 'pls': 0.3,\n",
       " 'plz': 0.3,\n",
       " 'pmbi': 0.8,\n",
       " 'pmfji': 0.3,\n",
       " 'pmji': 0.7,\n",
       " 'po': -2.6,\n",
       " 'ptl': 2.6,\n",
       " 'pu': -1.1,\n",
       " 'qq': -2.2,\n",
       " 'qt': 1.8,\n",
       " 'r&r': 2.4,\n",
       " 'rofl': 2.7,\n",
       " 'roflmao': 2.5,\n",
       " 'rotfl': 2.6,\n",
       " 'rotflmao': 2.8,\n",
       " 'rotflmfao': 2.5,\n",
       " 'rotflol': 3.0,\n",
       " 'rotgl': 2.9,\n",
       " 'rotglmao': 1.8,\n",
       " 's:': -1.1,\n",
       " 'sapfu': -1.1,\n",
       " 'sete': 2.8,\n",
       " 'sfete': 2.7,\n",
       " 'sgtm': 2.4,\n",
       " 'slap': 0.6,\n",
       " 'slaw': 2.1,\n",
       " 'smh': -1.3,\n",
       " 'snafu': -2.5,\n",
       " 'sob': -1.0,\n",
       " 'swak': 2.3,\n",
       " 'tgif': 2.3,\n",
       " 'thks': 1.4,\n",
       " 'thx': 1.5,\n",
       " 'tia': 2.3,\n",
       " 'tmi': -0.3,\n",
       " 'tnx': 1.1,\n",
       " 'true': 1.8,\n",
       " 'tx': 1.5,\n",
       " 'txs': 1.1,\n",
       " 'ty': 1.6,\n",
       " 'tyvm': 2.5,\n",
       " 'urw': 1.9,\n",
       " 'vbg': 2.1,\n",
       " 'vbs': 3.1,\n",
       " 'vip': 2.3,\n",
       " 'vwd': 2.6,\n",
       " 'vwp': 2.1,\n",
       " 'wag': -0.2,\n",
       " 'wd': 2.7,\n",
       " 'wilco': 0.9,\n",
       " 'wp': 1.0,\n",
       " 'wtf': -2.8,\n",
       " 'wtg': 2.1,\n",
       " 'wth': -2.4,\n",
       " 'x-d': 2.6,\n",
       " 'x-p': 1.7,\n",
       " 'xd': 2.8,\n",
       " 'xlnt': 3.0,\n",
       " 'xoxo': 3.0,\n",
       " 'xoxozzz': 2.3,\n",
       " 'xp': 1.6,\n",
       " 'xqzt': 1.6,\n",
       " 'xtc': 0.8,\n",
       " 'yolo': 1.1,\n",
       " 'yoyo': 0.4,\n",
       " 'yvw': 1.6,\n",
       " 'yw': 1.8,\n",
       " 'ywia': 2.5,\n",
       " 'zzz': -1.2,\n",
       " '[-;': 0.5,\n",
       " '[:': 1.3,\n",
       " '[;': 1.0,\n",
       " '[=': 1.7,\n",
       " '\\\\-:': -1.0,\n",
       " '\\\\:': -1.0,\n",
       " '\\\\:<': -1.7,\n",
       " '\\\\=': -1.1,\n",
       " '\\\\^:': -1.3,\n",
       " '\\\\o/': 2.2,\n",
       " '\\\\o:': -1.2,\n",
       " ']-:': -2.1,\n",
       " ']:': -1.6,\n",
       " ']:<': -2.5,\n",
       " '^<_<': 1.4,\n",
       " '^urs': -2.8,\n",
       " 'abandon': -1.9,\n",
       " 'abandoned': -2.0,\n",
       " 'abandoner': -1.9,\n",
       " 'abandoners': -1.9,\n",
       " 'abandoning': -1.6,\n",
       " 'abandonment': -2.4,\n",
       " 'abandonments': -1.7,\n",
       " 'abandons': -1.3,\n",
       " 'abducted': -2.3,\n",
       " 'abduction': -2.8,\n",
       " 'abductions': -2.0,\n",
       " 'abhor': -2.0,\n",
       " 'abhorred': -2.4,\n",
       " 'abhorrent': -3.1,\n",
       " 'abhors': -2.9,\n",
       " 'abilities': 1.0,\n",
       " 'ability': 1.3,\n",
       " 'aboard': 0.1,\n",
       " 'absentee': -1.1,\n",
       " 'absentees': -0.8,\n",
       " 'absolve': 1.2,\n",
       " 'absolved': 1.5,\n",
       " 'absolves': 1.3,\n",
       " 'absolving': 1.6,\n",
       " 'abuse': -3.2,\n",
       " 'abused': -2.3,\n",
       " 'abuser': -2.6,\n",
       " 'abusers': -2.6,\n",
       " 'abuses': -2.6,\n",
       " 'abusing': -2.0,\n",
       " 'abusive': -3.2,\n",
       " 'abusively': -2.8,\n",
       " 'abusiveness': -2.5,\n",
       " 'abusivenesses': -3.0,\n",
       " 'accept': 1.6,\n",
       " 'acceptabilities': 1.6,\n",
       " 'acceptability': 1.1,\n",
       " 'acceptable': 1.3,\n",
       " 'acceptableness': 1.3,\n",
       " 'acceptably': 1.5,\n",
       " 'acceptance': 2.0,\n",
       " 'acceptances': 1.7,\n",
       " 'acceptant': 1.6,\n",
       " 'acceptation': 1.3,\n",
       " 'acceptations': 0.9,\n",
       " 'accepted': 1.1,\n",
       " 'accepting': 1.6,\n",
       " 'accepts': 1.3,\n",
       " 'accident': -2.1,\n",
       " 'accidental': -0.3,\n",
       " 'accidentally': -1.4,\n",
       " 'accidents': -1.3,\n",
       " 'accomplish': 1.8,\n",
       " 'accomplished': 1.9,\n",
       " 'accomplishes': 1.7,\n",
       " 'accusation': -1.0,\n",
       " 'accusations': -1.3,\n",
       " 'accuse': -0.8,\n",
       " 'accused': -1.2,\n",
       " 'accuses': -1.4,\n",
       " 'accusing': -0.7,\n",
       " 'ache': -1.6,\n",
       " 'ached': -1.6,\n",
       " 'aches': -1.0,\n",
       " 'achievable': 1.3,\n",
       " 'aching': -2.2,\n",
       " 'acquit': 0.8,\n",
       " 'acquits': 0.1,\n",
       " 'acquitted': 1.0,\n",
       " 'acquitting': 1.3,\n",
       " 'acrimonious': -1.7,\n",
       " 'active': 1.7,\n",
       " 'actively': 1.3,\n",
       " 'activeness': 0.6,\n",
       " 'activenesses': 0.8,\n",
       " 'actives': 1.1,\n",
       " 'adequate': 0.9,\n",
       " 'admirability': 2.4,\n",
       " 'admirable': 2.6,\n",
       " 'admirableness': 2.2,\n",
       " 'admirably': 2.5,\n",
       " 'admiral': 1.3,\n",
       " 'admirals': 1.5,\n",
       " 'admiralties': 1.6,\n",
       " 'admiralty': 1.2,\n",
       " 'admiration': 2.5,\n",
       " 'admirations': 1.6,\n",
       " 'admire': 2.1,\n",
       " 'admired': 2.3,\n",
       " 'admirer': 1.8,\n",
       " 'admirers': 1.7,\n",
       " 'admires': 1.5,\n",
       " 'admiring': 1.6,\n",
       " 'admiringly': 2.3,\n",
       " 'admit': 0.8,\n",
       " 'admits': 1.2,\n",
       " 'admitted': 0.4,\n",
       " 'admonished': -1.9,\n",
       " 'adopt': 0.7,\n",
       " 'adopts': 0.7,\n",
       " 'adorability': 2.2,\n",
       " 'adorable': 2.2,\n",
       " 'adorableness': 2.5,\n",
       " 'adorably': 2.1,\n",
       " 'adoration': 2.9,\n",
       " 'adorations': 2.2,\n",
       " 'adore': 2.6,\n",
       " 'adored': 1.8,\n",
       " 'adorer': 1.7,\n",
       " 'adorers': 2.1,\n",
       " 'adores': 1.6,\n",
       " 'adoring': 2.6,\n",
       " 'adoringly': 2.4,\n",
       " 'adorn': 0.9,\n",
       " 'adorned': 0.8,\n",
       " 'adorner': 1.3,\n",
       " 'adorners': 0.9,\n",
       " 'adorning': 1.0,\n",
       " 'adornment': 1.3,\n",
       " 'adornments': 0.8,\n",
       " 'adorns': 0.5,\n",
       " 'advanced': 1.0,\n",
       " 'advantage': 1.0,\n",
       " 'advantaged': 1.4,\n",
       " 'advantageous': 1.5,\n",
       " 'advantageously': 1.9,\n",
       " 'advantageousness': 1.6,\n",
       " 'advantages': 1.5,\n",
       " 'advantaging': 1.6,\n",
       " 'adventure': 1.3,\n",
       " 'adventured': 1.3,\n",
       " 'adventurer': 1.2,\n",
       " 'adventurers': 0.9,\n",
       " 'adventures': 1.4,\n",
       " 'adventuresome': 1.7,\n",
       " 'adventuresomeness': 1.3,\n",
       " 'adventuress': 0.8,\n",
       " 'adventuresses': 1.4,\n",
       " 'adventuring': 2.3,\n",
       " 'adventurism': 1.5,\n",
       " 'adventurist': 1.4,\n",
       " 'adventuristic': 1.7,\n",
       " 'adventurists': 1.2,\n",
       " 'adventurous': 1.4,\n",
       " 'adventurously': 1.3,\n",
       " 'adventurousness': 1.8,\n",
       " 'adversarial': -1.5,\n",
       " 'adversaries': -1.0,\n",
       " 'adversary': -0.8,\n",
       " 'adversative': -1.2,\n",
       " 'adversatively': -0.1,\n",
       " 'adversatives': -1.0,\n",
       " 'adverse': -1.5,\n",
       " 'adversely': -0.8,\n",
       " 'adverseness': -0.6,\n",
       " 'adversities': -1.5,\n",
       " 'adversity': -1.8,\n",
       " 'affected': -0.6,\n",
       " 'affection': 2.4,\n",
       " 'affectional': 1.9,\n",
       " 'affectionally': 1.5,\n",
       " 'affectionate': 1.9,\n",
       " 'affectionately': 2.2,\n",
       " 'affectioned': 1.8,\n",
       " 'affectionless': -2.0,\n",
       " 'affections': 1.5,\n",
       " 'afflicted': -1.5,\n",
       " 'affronted': 0.2,\n",
       " 'aggravate': -2.5,\n",
       " 'aggravated': -1.9,\n",
       " 'aggravates': -1.9,\n",
       " 'aggravating': -1.2,\n",
       " 'aggress': -1.3,\n",
       " 'aggressed': -1.4,\n",
       " 'aggresses': -0.5,\n",
       " 'aggressing': -0.6,\n",
       " 'aggression': -1.2,\n",
       " 'aggressions': -1.3,\n",
       " 'aggressive': -0.6,\n",
       " 'aggressively': -1.3,\n",
       " 'aggressiveness': -1.8,\n",
       " 'aggressivities': -1.4,\n",
       " 'aggressivity': -0.6,\n",
       " 'aggressor': -0.8,\n",
       " 'aggressors': -0.9,\n",
       " 'aghast': -1.9,\n",
       " 'agitate': -1.7,\n",
       " 'agitated': -2.0,\n",
       " 'agitatedly': -1.6,\n",
       " 'agitates': -1.4,\n",
       " 'agitating': -1.8,\n",
       " 'agitation': -1.0,\n",
       " 'agitational': -1.2,\n",
       " 'agitations': -1.3,\n",
       " 'agitative': -1.3,\n",
       " 'agitato': -0.1,\n",
       " 'agitator': -1.4,\n",
       " 'agitators': -2.1,\n",
       " 'agog': 1.9,\n",
       " 'agonise': -2.1,\n",
       " 'agonised': -2.3,\n",
       " 'agonises': -2.4,\n",
       " 'agonising': -1.5,\n",
       " 'agonize': -2.3,\n",
       " 'agonized': -2.2,\n",
       " 'agonizes': -2.3,\n",
       " 'agonizing': -2.7,\n",
       " 'agonizingly': -2.3,\n",
       " 'agony': -1.8,\n",
       " 'agree': 1.5,\n",
       " 'agreeability': 1.9,\n",
       " 'agreeable': 1.8,\n",
       " 'agreeableness': 1.8,\n",
       " 'agreeablenesses': 1.3,\n",
       " 'agreeably': 1.6,\n",
       " 'agreed': 1.1,\n",
       " 'agreeing': 1.4,\n",
       " 'agreement': 2.2,\n",
       " 'agreements': 1.1,\n",
       " 'agrees': 0.8,\n",
       " 'alarm': -1.4,\n",
       " 'alarmed': -1.4,\n",
       " 'alarming': -0.5,\n",
       " 'alarmingly': -2.6,\n",
       " 'alarmism': -0.3,\n",
       " 'alarmists': -1.1,\n",
       " 'alarms': -1.1,\n",
       " 'alas': -1.1,\n",
       " 'alert': 1.2,\n",
       " 'alienation': -1.1,\n",
       " 'alive': 1.6,\n",
       " 'allergic': -1.2,\n",
       " 'allow': 0.9,\n",
       " 'alone': -1.0,\n",
       " 'alright': 1.0,\n",
       " 'amaze': 2.5,\n",
       " 'amazed': 2.2,\n",
       " 'amazedly': 2.1,\n",
       " 'amazement': 2.5,\n",
       " 'amazements': 2.2,\n",
       " 'amazes': 2.2,\n",
       " 'amazing': 2.8,\n",
       " 'amazon': 0.7,\n",
       " 'amazonite': 0.2,\n",
       " 'amazons': -0.1,\n",
       " 'amazonstone': 1.0,\n",
       " 'amazonstones': 0.2,\n",
       " 'ambitious': 2.1,\n",
       " 'ambivalent': 0.5,\n",
       " 'amor': 3.0,\n",
       " 'amoral': -1.6,\n",
       " 'amoralism': -0.7,\n",
       " 'amoralisms': -0.7,\n",
       " 'amoralities': -1.2,\n",
       " 'amorality': -1.5,\n",
       " 'amorally': -1.0,\n",
       " 'amoretti': 0.2,\n",
       " 'amoretto': 0.6,\n",
       " 'amorettos': 0.3,\n",
       " 'amorino': 1.2,\n",
       " 'amorist': 1.6,\n",
       " 'amoristic': 1.0,\n",
       " 'amorists': 0.1,\n",
       " 'amoroso': 2.3,\n",
       " 'amorous': 1.8,\n",
       " 'amorously': 2.3,\n",
       " 'amorousness': 2.0,\n",
       " 'amorphous': -0.2,\n",
       " 'amorphously': 0.1,\n",
       " 'amorphousness': 0.3,\n",
       " 'amort': -2.1,\n",
       " 'amortise': 0.5,\n",
       " 'amortised': -0.2,\n",
       " 'amortises': 0.1,\n",
       " 'amortizable': 0.5,\n",
       " 'amortization': 0.6,\n",
       " 'amortizations': 0.2,\n",
       " 'amortize': -0.1,\n",
       " 'amortized': 0.8,\n",
       " 'amortizes': 0.6,\n",
       " 'amortizing': 0.8,\n",
       " 'amusable': 0.7,\n",
       " 'amuse': 1.7,\n",
       " 'amused': 1.8,\n",
       " 'amusedly': 2.2,\n",
       " 'amusement': 1.5,\n",
       " 'amusements': 1.5,\n",
       " 'amuser': 1.1,\n",
       " 'amusers': 1.3,\n",
       " 'amuses': 1.7,\n",
       " 'amusia': 0.3,\n",
       " 'amusias': -0.4,\n",
       " 'amusing': 1.6,\n",
       " 'amusingly': 0.8,\n",
       " 'amusingness': 1.8,\n",
       " 'amusive': 1.7,\n",
       " 'anger': -2.7,\n",
       " 'angered': -2.3,\n",
       " 'angering': -2.2,\n",
       " 'angerly': -1.9,\n",
       " 'angers': -2.3,\n",
       " 'angrier': -2.3,\n",
       " 'angriest': -3.1,\n",
       " 'angrily': -1.8,\n",
       " 'angriness': -1.7,\n",
       " 'angry': -2.3,\n",
       " 'anguish': -2.9,\n",
       " 'anguished': -1.8,\n",
       " 'anguishes': -2.1,\n",
       " 'anguishing': -2.7,\n",
       " 'animosity': -1.9,\n",
       " 'annoy': -1.9,\n",
       " 'annoyance': -1.3,\n",
       " 'annoyances': -1.8,\n",
       " 'annoyed': -1.6,\n",
       " 'annoyer': -2.2,\n",
       " 'annoyers': -1.5,\n",
       " 'annoying': -1.7,\n",
       " 'annoys': -1.8,\n",
       " 'antagonism': -1.9,\n",
       " 'antagonisms': -1.2,\n",
       " 'antagonist': -1.9,\n",
       " 'antagonistic': -1.7,\n",
       " 'antagonistically': -2.2,\n",
       " 'antagonists': -1.7,\n",
       " 'antagonize': -2.0,\n",
       " 'antagonized': -1.4,\n",
       " 'antagonizes': -0.5,\n",
       " 'antagonizing': -2.7,\n",
       " 'anti': -1.3,\n",
       " 'anticipation': 0.4,\n",
       " 'anxieties': -0.6,\n",
       " 'anxiety': -0.7,\n",
       " 'anxious': -1.0,\n",
       " 'anxiously': -0.9,\n",
       " 'anxiousness': -1.0,\n",
       " 'aok': 2.0,\n",
       " 'apathetic': -1.2,\n",
       " 'apathetically': -0.4,\n",
       " 'apathies': -0.6,\n",
       " 'apathy': -1.2,\n",
       " 'apeshit': -0.9,\n",
       " 'apocalyptic': -3.4,\n",
       " 'apologise': 1.6,\n",
       " 'apologised': 0.4,\n",
       " 'apologises': 0.8,\n",
       " 'apologising': 0.2,\n",
       " 'apologize': 0.4,\n",
       " 'apologized': 1.3,\n",
       " 'apologizes': 1.5,\n",
       " 'apologizing': -0.3,\n",
       " 'apology': 0.2,\n",
       " 'appall': -2.4,\n",
       " 'appalled': -2.0,\n",
       " 'appalling': -1.5,\n",
       " 'appallingly': -2.0,\n",
       " 'appalls': -1.9,\n",
       " 'appease': 1.1,\n",
       " 'appeased': 0.9,\n",
       " 'appeases': 0.9,\n",
       " 'appeasing': 1.0,\n",
       " 'applaud': 2.0,\n",
       " 'applauded': 1.5,\n",
       " 'applauding': 2.1,\n",
       " 'applauds': 1.4,\n",
       " 'applause': 1.8,\n",
       " 'appreciate': 1.7,\n",
       " 'appreciated': 2.3,\n",
       " 'appreciates': 2.3,\n",
       " 'appreciating': 1.9,\n",
       " 'appreciation': 2.3,\n",
       " 'appreciations': 1.7,\n",
       " 'appreciative': 2.6,\n",
       " 'appreciatively': 1.8,\n",
       " 'appreciativeness': 1.6,\n",
       " 'appreciator': 2.6,\n",
       " 'appreciators': 1.5,\n",
       " 'appreciatory': 1.7,\n",
       " 'apprehensible': 1.1,\n",
       " 'apprehensibly': -0.2,\n",
       " 'apprehension': -2.1,\n",
       " 'apprehensions': -0.9,\n",
       " 'apprehensively': -0.3,\n",
       " 'apprehensiveness': -0.7,\n",
       " 'approval': 2.1,\n",
       " 'approved': 1.8,\n",
       " 'approves': 1.7,\n",
       " 'ardent': 2.1,\n",
       " 'arguable': -1.0,\n",
       " 'arguably': -1.0,\n",
       " 'argue': -1.4,\n",
       " 'argued': -1.5,\n",
       " 'arguer': -1.6,\n",
       " 'arguers': -1.4,\n",
       " 'argues': -1.6,\n",
       " 'arguing': -2.0,\n",
       " 'argument': -1.5,\n",
       " 'argumentative': -1.5,\n",
       " 'argumentatively': -1.8,\n",
       " 'argumentive': -1.5,\n",
       " 'arguments': -1.7,\n",
       " 'arrest': -1.4,\n",
       " 'arrested': -2.1,\n",
       " 'arrests': -1.9,\n",
       " 'arrogance': -2.4,\n",
       " 'arrogances': -1.9,\n",
       " 'arrogant': -2.2,\n",
       " 'arrogantly': -1.8,\n",
       " 'ashamed': -2.1,\n",
       " 'ashamedly': -1.7,\n",
       " 'ass': -2.5,\n",
       " 'assassination': -2.9,\n",
       " 'assassinations': -2.7,\n",
       " 'assault': -2.8,\n",
       " 'assaulted': -2.4,\n",
       " 'assaulting': -2.3,\n",
       " 'assaultive': -2.8,\n",
       " 'assaults': -2.5,\n",
       " 'asset': 1.5,\n",
       " 'assets': 0.7,\n",
       " 'assfucking': -2.5,\n",
       " 'assholes': -2.8,\n",
       " 'assurance': 1.4,\n",
       " 'assurances': 1.4,\n",
       " 'assure': 1.4,\n",
       " 'assured': 1.5,\n",
       " 'assuredly': 1.6,\n",
       " 'assuredness': 1.4,\n",
       " 'assurer': 0.9,\n",
       " 'assurers': 1.1,\n",
       " 'assures': 1.3,\n",
       " 'assurgent': 1.3,\n",
       " 'assuring': 1.6,\n",
       " 'assuror': 0.5,\n",
       " 'assurors': 0.7,\n",
       " 'astonished': 1.6,\n",
       " 'astound': 1.7,\n",
       " 'astounded': 1.8,\n",
       " 'astounding': 1.8,\n",
       " 'astoundingly': 2.1,\n",
       " 'astounds': 2.1,\n",
       " 'attachment': 1.2,\n",
       " 'attachments': 1.1,\n",
       " 'attack': -2.1,\n",
       " 'attacked': -2.0,\n",
       " 'attacker': -2.7,\n",
       " 'attackers': -2.7,\n",
       " 'attacking': -2.0,\n",
       " 'attacks': -1.9,\n",
       " 'attract': 1.5,\n",
       " 'attractancy': 0.9,\n",
       " 'attractant': 1.3,\n",
       " 'attractants': 1.4,\n",
       " 'attracted': 1.8,\n",
       " 'attracting': 2.1,\n",
       " 'attraction': 2.0,\n",
       " 'attractions': 1.8,\n",
       " 'attractive': 1.9,\n",
       " 'attractively': 2.2,\n",
       " 'attractiveness': 1.8,\n",
       " 'attractivenesses': 2.1,\n",
       " 'attractor': 1.2,\n",
       " 'attractors': 1.2,\n",
       " 'attracts': 1.7,\n",
       " 'audacious': 0.9,\n",
       " 'authority': 0.3,\n",
       " 'aversion': -1.9,\n",
       " 'aversions': -1.1,\n",
       " 'aversive': -1.6,\n",
       " 'aversively': -0.8,\n",
       " 'avert': -0.7,\n",
       " 'averted': -0.3,\n",
       " 'averts': -0.4,\n",
       " 'avid': 1.2,\n",
       " 'avoid': -1.2,\n",
       " 'avoidance': -1.7,\n",
       " 'avoidances': -1.1,\n",
       " 'avoided': -1.4,\n",
       " 'avoider': -1.8,\n",
       " 'avoiders': -1.4,\n",
       " 'avoiding': -1.4,\n",
       " 'avoids': -0.7,\n",
       " 'await': 0.4,\n",
       " 'awaited': -0.1,\n",
       " 'awaits': 0.3,\n",
       " 'award': 2.5,\n",
       " 'awardable': 2.4,\n",
       " 'awarded': 1.7,\n",
       " 'awardee': 1.8,\n",
       " 'awardees': 1.2,\n",
       " 'awarder': 0.9,\n",
       " 'awarders': 1.3,\n",
       " 'awarding': 1.9,\n",
       " 'awards': 2.0,\n",
       " 'awesome': 3.1,\n",
       " 'awful': -2.0,\n",
       " 'awkward': -0.6,\n",
       " 'awkwardly': -1.3,\n",
       " 'awkwardness': -0.7,\n",
       " 'axe': -0.4,\n",
       " 'axed': -1.3,\n",
       " 'backed': 0.1,\n",
       " 'backing': 0.1,\n",
       " 'backs': -0.2,\n",
       " 'bad': -2.5,\n",
       " 'badass': -0.6,\n",
       " 'badly': -2.1,\n",
       " 'bailout': -0.4,\n",
       " 'bamboozle': -1.5,\n",
       " 'bamboozled': -1.5,\n",
       " 'bamboozles': -1.5,\n",
       " 'ban': -2.6,\n",
       " 'banish': -1.9,\n",
       " 'bankrupt': -2.6,\n",
       " 'bankster': -2.1,\n",
       " 'banned': -2.0,\n",
       " 'bargain': 0.8,\n",
       " 'barrier': -0.5,\n",
       " 'bashful': -0.1,\n",
       " 'bashfully': 0.2,\n",
       " 'bashfulness': -0.8,\n",
       " 'bastard': -2.5,\n",
       " 'bastardies': -1.8,\n",
       " 'bastardise': -2.1,\n",
       " 'bastardised': -2.3,\n",
       " 'bastardises': -2.3,\n",
       " 'bastardising': -2.6,\n",
       " 'bastardization': -2.4,\n",
       " 'bastardizations': -2.1,\n",
       " 'bastardize': -2.4,\n",
       " 'bastardized': -2.0,\n",
       " 'bastardizes': -1.8,\n",
       " 'bastardizing': -2.3,\n",
       " 'bastardly': -2.7,\n",
       " 'bastards': -3.0,\n",
       " 'bastardy': -2.7,\n",
       " 'battle': -1.6,\n",
       " 'battled': -1.2,\n",
       " 'battlefield': -1.6,\n",
       " 'battlefields': -0.9,\n",
       " 'battlefront': -1.2,\n",
       " 'battlefronts': -0.8,\n",
       " 'battleground': -1.7,\n",
       " 'battlegrounds': -0.6,\n",
       " 'battlement': -0.4,\n",
       " 'battlements': -0.4,\n",
       " 'battler': -0.8,\n",
       " 'battlers': -0.2,\n",
       " 'battles': -1.6,\n",
       " 'battleship': -0.1,\n",
       " 'battleships': -0.5,\n",
       " 'battlewagon': -0.3,\n",
       " 'battlewagons': -0.5,\n",
       " 'battling': -1.1,\n",
       " 'beaten': -1.8,\n",
       " 'beatific': 1.8,\n",
       " 'beating': -2.0,\n",
       " 'beaut': 1.6,\n",
       " 'beauteous': 2.5,\n",
       " 'beauteously': 2.6,\n",
       " 'beauteousness': 2.7,\n",
       " 'beautician': 1.2,\n",
       " 'beauticians': 0.4,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7502"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sid.lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"( '}{' )\", 1.6),\n",
       " (\"can't stand\", -2.0),\n",
       " ('fed up', -1.8),\n",
       " ('screwed up', -1.5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check n-grams\n",
    "\n",
    "[(token, score) for token, score in sid.lexicon.items() if \" \" in token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that emoticons are also part of this lexicon of 7502 tokens. From these tokens, only 3 of them are n-grams - bigrams in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Add scores and new labels to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll append 3 columns to our dataset:\n",
    "* `scores` with the polarity scores (negative, neutral, positive and compound)\n",
    "* `compound` with the extracted compound score\n",
    "* `comp_label` with the label derived from the compound score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_label  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "df['comp_label'] = df['compound'].apply(lambda comp: 'pos' if comp >=0 else 'neg')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Compare the original label with the new label and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4468  435]\n",
      " [2474 2623]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "print(confusion_matrix(df['label'], df['comp_label'], labels =['pos', 'neg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.51      0.64      5097\n",
      "         pos       0.64      0.91      0.75      4903\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(df['label'], df['comp_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7091\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print(accuracy_score(df['label'], df['comp_label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER **was not very accurate**, but still it was able to correctly identify about **71%** of the reviews as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a rule-based algorithm like VADER, we can build a **machine learning model** from labeled data - this is the second step of this project. We'll use a **Naive Bayes** model to do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Tokenize reviews with casual_tokenize and create a bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casual_tokenize was built to deal with short and informal texts from social networks, and is able to deal with emoticons, hashtags and other specificities of this kind of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = []\n",
    "from collections import Counter\n",
    "for review in df['review']:\n",
    "    bow.append(Counter(casual_tokenize(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'Stuning': 1,\n",
       "          'even': 2,\n",
       "          'for': 1,\n",
       "          'the': 5,\n",
       "          'non-gamer': 1,\n",
       "          ':': 1,\n",
       "          'This': 1,\n",
       "          'sound': 1,\n",
       "          'track': 1,\n",
       "          'was': 1,\n",
       "          'beautiful': 1,\n",
       "          '!': 4,\n",
       "          'It': 3,\n",
       "          'paints': 1,\n",
       "          'senery': 1,\n",
       "          'in': 1,\n",
       "          'your': 1,\n",
       "          'mind': 1,\n",
       "          'so': 1,\n",
       "          'well': 1,\n",
       "          'I': 3,\n",
       "          'would': 2,\n",
       "          'recomend': 1,\n",
       "          'it': 2,\n",
       "          'to': 2,\n",
       "          'people': 1,\n",
       "          'who': 2,\n",
       "          'hate': 1,\n",
       "          'vid': 1,\n",
       "          '.': 2,\n",
       "          'game': 2,\n",
       "          'music': 2,\n",
       "          'have': 2,\n",
       "          'played': 2,\n",
       "          'Chrono': 1,\n",
       "          'Cross': 1,\n",
       "          'but': 1,\n",
       "          'out': 1,\n",
       "          'of': 2,\n",
       "          'all': 1,\n",
       "          'games': 1,\n",
       "          'ever': 1,\n",
       "          'has': 1,\n",
       "          'best': 1,\n",
       "          'backs': 1,\n",
       "          'away': 1,\n",
       "          'from': 1,\n",
       "          'crude': 1,\n",
       "          'keyboarding': 1,\n",
       "          'and': 2,\n",
       "          'takes': 1,\n",
       "          'a': 1,\n",
       "          'fresher': 1,\n",
       "          'step': 1,\n",
       "          'with': 1,\n",
       "          'grate': 1,\n",
       "          'guitars': 1,\n",
       "          'soulful': 1,\n",
       "          'orchestras': 1,\n",
       "          'impress': 1,\n",
       "          'anyone': 1,\n",
       "          'cares': 1,\n",
       "          'listen': 1,\n",
       "          '^': 2,\n",
       "          '_': 1}),\n",
       " Counter({'The': 2,\n",
       "          'best': 2,\n",
       "          'soundtrack': 2,\n",
       "          'ever': 1,\n",
       "          'to': 5,\n",
       "          'anything': 1,\n",
       "          '.': 4,\n",
       "          ':': 1,\n",
       "          \"I'm\": 2,\n",
       "          'reading': 1,\n",
       "          'a': 3,\n",
       "          'lot': 1,\n",
       "          'of': 1,\n",
       "          'reviews': 1,\n",
       "          'saying': 1,\n",
       "          'that': 3,\n",
       "          'this': 4,\n",
       "          'is': 5,\n",
       "          'the': 2,\n",
       "          \"'\": 2,\n",
       "          'game': 1,\n",
       "          'and': 3,\n",
       "          'I': 3,\n",
       "          'figured': 1,\n",
       "          \"I'd\": 1,\n",
       "          'write': 1,\n",
       "          'review': 1,\n",
       "          'disagree': 1,\n",
       "          'bit': 1,\n",
       "          'This': 1,\n",
       "          'in': 1,\n",
       "          'my': 1,\n",
       "          'opinino': 1,\n",
       "          'Yasunori': 1,\n",
       "          \"Mitsuda's\": 1,\n",
       "          'ultimate': 1,\n",
       "          'masterpiece': 1,\n",
       "          'music': 1,\n",
       "          'timeless': 1,\n",
       "          'been': 1,\n",
       "          'listening': 1,\n",
       "          'it': 1,\n",
       "          'for': 2,\n",
       "          'years': 1,\n",
       "          'now': 1,\n",
       "          'its': 1,\n",
       "          'beauty': 1,\n",
       "          'simply': 1,\n",
       "          'refuses': 1,\n",
       "          'fade.The': 1,\n",
       "          'price': 1,\n",
       "          'tag': 1,\n",
       "          'on': 1,\n",
       "          'pretty': 1,\n",
       "          'staggering': 1,\n",
       "          'must': 1,\n",
       "          'say': 1,\n",
       "          ',': 2,\n",
       "          'but': 1,\n",
       "          'if': 1,\n",
       "          'you': 1,\n",
       "          'are': 1,\n",
       "          'going': 1,\n",
       "          'buy': 1,\n",
       "          'any': 1,\n",
       "          'cd': 1,\n",
       "          'much': 1,\n",
       "          'money': 1,\n",
       "          'only': 1,\n",
       "          'one': 1,\n",
       "          'feel': 1,\n",
       "          'would': 1,\n",
       "          'be': 1,\n",
       "          'worth': 1,\n",
       "          'every': 1,\n",
       "          'penny': 1})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first two elements of bow\n",
    "\n",
    "bow[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our variable `bow` is a list of \"Counter dictionaries\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a dataframe with the from_records() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = pd.DataFrame.from_records(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stuning</th>\n",
       "      <th>even</th>\n",
       "      <th>for</th>\n",
       "      <th>the</th>\n",
       "      <th>non-gamer</th>\n",
       "      <th>:</th>\n",
       "      <th>This</th>\n",
       "      <th>sound</th>\n",
       "      <th>track</th>\n",
       "      <th>was</th>\n",
       "      <th>...</th>\n",
       "      <th>Journalism</th>\n",
       "      <th>plucky</th>\n",
       "      <th>strives</th>\n",
       "      <th>reworked</th>\n",
       "      <th>bolstered</th>\n",
       "      <th>midwestern</th>\n",
       "      <th>Pen</th>\n",
       "      <th>Montblanc</th>\n",
       "      <th>raves</th>\n",
       "      <th>Graduation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stuning  even  for  the  non-gamer    :  This  sound  track  was  ...  \\\n",
       "0      1.0   2.0  1.0  5.0        1.0  1.0   1.0    1.0    1.0  1.0  ...   \n",
       "1      NaN   NaN  2.0  2.0        NaN  1.0   1.0    NaN    NaN  NaN  ...   \n",
       "2      NaN   1.0  1.0  9.0        NaN  1.0   1.0    NaN    NaN  NaN  ...   \n",
       "3      NaN   NaN  NaN  2.0        NaN  3.0   NaN    NaN    NaN  NaN  ...   \n",
       "4      NaN   NaN  NaN  5.0        NaN  4.0   1.0    NaN    NaN  NaN  ...   \n",
       "\n",
       "   Journalism  plucky  strives  reworked  bolstered  midwestern  Pen  \\\n",
       "0         NaN     NaN      NaN       NaN        NaN         NaN  NaN   \n",
       "1         NaN     NaN      NaN       NaN        NaN         NaN  NaN   \n",
       "2         NaN     NaN      NaN       NaN        NaN         NaN  NaN   \n",
       "3         NaN     NaN      NaN       NaN        NaN         NaN  NaN   \n",
       "4         NaN     NaN      NaN       NaN        NaN         NaN  NaN   \n",
       "\n",
       "   Montblanc  raves  Graduation  \n",
       "0        NaN    NaN         NaN  \n",
       "1        NaN    NaN         NaN  \n",
       "2        NaN    NaN         NaN  \n",
       "3        NaN    NaN         NaN  \n",
       "4        NaN    NaN         NaN  \n",
       "\n",
       "[5 rows x 46435 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fill all the NaN's  with zeros and set the numbers to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = df_bow.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stuning</th>\n",
       "      <th>even</th>\n",
       "      <th>for</th>\n",
       "      <th>the</th>\n",
       "      <th>non-gamer</th>\n",
       "      <th>:</th>\n",
       "      <th>This</th>\n",
       "      <th>sound</th>\n",
       "      <th>track</th>\n",
       "      <th>was</th>\n",
       "      <th>...</th>\n",
       "      <th>Journalism</th>\n",
       "      <th>plucky</th>\n",
       "      <th>strives</th>\n",
       "      <th>reworked</th>\n",
       "      <th>bolstered</th>\n",
       "      <th>midwestern</th>\n",
       "      <th>Pen</th>\n",
       "      <th>Montblanc</th>\n",
       "      <th>raves</th>\n",
       "      <th>Graduation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46435 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stuning  even  for  the  non-gamer  :  This  sound  track  was  ...  \\\n",
       "0        1     2    1    5          1  1     1      1      1    1  ...   \n",
       "1        0     0    2    2          0  1     1      0      0    0  ...   \n",
       "2        0     1    1    9          0  1     1      0      0    0  ...   \n",
       "3        0     0    0    2          0  3     0      0      0    0  ...   \n",
       "4        0     0    0    5          0  4     1      0      0    0  ...   \n",
       "\n",
       "   Journalism  plucky  strives  reworked  bolstered  midwestern  Pen  \\\n",
       "0           0       0        0         0          0           0    0   \n",
       "1           0       0        0         0          0           0    0   \n",
       "2           0       0        0         0          0           0    0   \n",
       "3           0       0        0         0          0           0    0   \n",
       "4           0       0        0         0          0           0    0   \n",
       "\n",
       "   Montblanc  raves  Graduation  \n",
       "0          0      0           0  \n",
       "1          0      0           0  \n",
       "2          0      0           0  \n",
       "3          0      0           0  \n",
       "4          0      0           0  \n",
       "\n",
       "[5 rows x 46435 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 46435)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our 10 000 reviews, we have a total of 46435 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_label  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check reviews dataframe\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_bow, df['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "\n",
    "my_model = MultinomialNB()\n",
    "my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "predicted_sentiment = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'neg', 'neg', 'neg',\n",
       "       'neg'], dtype='<U3')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 predictions\n",
    "\n",
    "predicted_sentiment[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Compare the original label with the new label and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1125  357]\n",
      " [ 164 1354]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predicted_sentiment, labels =['pos', 'neg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.79      0.89      0.84      1518\n",
      "         pos       0.87      0.76      0.81      1482\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.83      0.83      0.83      3000\n",
      "weighted avg       0.83      0.83      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, predicted_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8263333333333334\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "\n",
    "print(accuracy_score(y_test, predicted_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this simple model, we have managed to improve our accuracy. Our **Naive Bayes model** was able to correctly identify about **83%** of the reviews of the test set as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to improve this model by:\n",
    "* trying different text vectorizaton methods \n",
    "* tune the hyperparameter alpha of our model (default value is 1.0)\n",
    "\n",
    "This will be the third step of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest text vectorization method is a **bag-of-words (BoW**) model based on simple counts of how many times each word appears on a given text (frequency), that we used in step 2. **One-hot-encoding** and **TF-IDF (Term Frequence-Inverse Document Frequency)** are the other methods we'll implement in this step. In order to do this, we will use **sklearn's CountVectorizer** and **TfidfVectorizer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Vectorize text : BoW, one-hot encoding and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use casual_tokenize as our tokenizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer(tokenizer=casual_tokenize)\n",
    "ohe_vectorizer = CountVectorizer(binary=True, tokenizer=casual_tokenize)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "\n",
    "cv_bow = bow_vectorizer.fit_transform(df['review'])\n",
    "cv_ohe = ohe_vectorizer.fit_transform(df['review'])\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create dataframes with the vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stuning': 32284,\n",
       " 'even': 12003,\n",
       " 'for': 13522,\n",
       " 'the': 33429,\n",
       " 'non-gamer': 22931,\n",
       " ':': 1044,\n",
       " 'this': 33634,\n",
       " 'sound': 31277,\n",
       " 'track': 34260,\n",
       " 'was': 36396,\n",
       " 'beautiful': 3848,\n",
       " '!': 0,\n",
       " 'it': 17976,\n",
       " 'paints': 24265,\n",
       " 'senery': 29789,\n",
       " 'in': 17049,\n",
       " 'your': 37601,\n",
       " 'mind': 21437,\n",
       " 'so': 30988,\n",
       " 'well': 36616,\n",
       " 'i': 16691,\n",
       " 'would': 37291,\n",
       " 'recomend': 27490,\n",
       " 'to': 33978,\n",
       " 'people': 24722,\n",
       " 'who': 36835,\n",
       " 'hate': 15622,\n",
       " 'vid': 35970,\n",
       " '.': 38,\n",
       " 'game': 14153,\n",
       " 'music': 22265,\n",
       " 'have': 15653,\n",
       " 'played': 25322,\n",
       " 'chrono': 6653,\n",
       " 'cross': 8481,\n",
       " 'but': 5448,\n",
       " 'out': 23908,\n",
       " 'of': 23398,\n",
       " 'all': 1973,\n",
       " 'games': 14179,\n",
       " 'ever': 12017,\n",
       " 'has': 15597,\n",
       " 'best': 4125,\n",
       " 'backs': 3473,\n",
       " 'away': 3336,\n",
       " 'from': 13888,\n",
       " 'crude': 8512,\n",
       " 'keyboarding': 18684,\n",
       " 'and': 2291,\n",
       " 'takes': 32968,\n",
       " 'a': 1099,\n",
       " 'fresher': 13827,\n",
       " 'step': 31915,\n",
       " 'with': 37039,\n",
       " 'grate': 14968,\n",
       " 'guitars': 15218,\n",
       " 'soulful': 31268,\n",
       " 'orchestras': 23750,\n",
       " 'impress': 17010,\n",
       " 'anyone': 2537,\n",
       " 'cares': 5845,\n",
       " 'listen': 19808,\n",
       " '^': 1085,\n",
       " '_': 1086,\n",
       " 'soundtrack': 31297,\n",
       " 'anything': 2542,\n",
       " \"i'm\": 16695,\n",
       " 'reading': 27309,\n",
       " 'lot': 20072,\n",
       " 'reviews': 28378,\n",
       " 'saying': 29242,\n",
       " 'that': 33416,\n",
       " 'is': 17922,\n",
       " \"'\": 22,\n",
       " 'figured': 13031,\n",
       " \"i'd\": 16693,\n",
       " 'write': 37345,\n",
       " 'review': 28366,\n",
       " 'disagree': 9902,\n",
       " 'bit': 4316,\n",
       " 'my': 22343,\n",
       " 'opinino': 23681,\n",
       " 'yasunori': 37491,\n",
       " \"mitsuda's\": 21648,\n",
       " 'ultimate': 34902,\n",
       " 'masterpiece': 20781,\n",
       " 'timeless': 33891,\n",
       " 'been': 3904,\n",
       " 'listening': 19817,\n",
       " 'years': 37515,\n",
       " 'now': 23143,\n",
       " 'its': 18077,\n",
       " 'beauty': 3855,\n",
       " 'simply': 30502,\n",
       " 'refuses': 27702,\n",
       " 'fade.the': 12573,\n",
       " 'price': 26129,\n",
       " 'tag': 32944,\n",
       " 'on': 23543,\n",
       " 'pretty': 26102,\n",
       " 'staggering': 31707,\n",
       " 'must': 22304,\n",
       " 'say': 29237,\n",
       " ',': 32,\n",
       " 'if': 16788,\n",
       " 'you': 37570,\n",
       " 'are': 2755,\n",
       " 'going': 14723,\n",
       " 'buy': 5473,\n",
       " 'any': 2526,\n",
       " 'cd': 6068,\n",
       " 'much': 22156,\n",
       " 'money': 21784,\n",
       " 'only': 23621,\n",
       " 'one': 23565,\n",
       " 'feel': 12887,\n",
       " 'be': 3783,\n",
       " 'worth': 37276,\n",
       " 'every': 12037,\n",
       " 'penny': 24711,\n",
       " 'amazing': 2154,\n",
       " 'favorite': 12825,\n",
       " 'time': 33863,\n",
       " 'hands': 15431,\n",
       " 'down': 10512,\n",
       " 'intense': 17616,\n",
       " 'sadness': 29026,\n",
       " '\"': 1,\n",
       " 'prisoners': 26210,\n",
       " 'fate': 12787,\n",
       " '(': 23,\n",
       " 'which': 36775,\n",
       " 'means': 21013,\n",
       " 'more': 21913,\n",
       " \"you've\": 37574,\n",
       " ')': 27,\n",
       " 'hope': 16337,\n",
       " 'distant': 10181,\n",
       " 'promise': 26391,\n",
       " 'girl': 14544,\n",
       " 'stole': 32018,\n",
       " 'star': 31771,\n",
       " 'an': 2248,\n",
       " 'important': 16983,\n",
       " 'inspiration': 17497,\n",
       " 'me': 20965,\n",
       " 'personally': 24869,\n",
       " 'throughout': 33752,\n",
       " 'teen': 33176,\n",
       " 'higher': 16053,\n",
       " 'energy': 11560,\n",
       " 'tracks': 34270,\n",
       " 'like': 19683,\n",
       " '~': 37755,\n",
       " \"time's\": 33864,\n",
       " 'scar': 29281,\n",
       " 'dreamwatch': 10622,\n",
       " 'chronomantique': 6659,\n",
       " 'indefinably': 17191,\n",
       " 'remeniscent': 27927,\n",
       " 'trigger': 34516,\n",
       " 'absolutely': 1208,\n",
       " 'superb': 32558,\n",
       " 'as': 2904,\n",
       " 'well.this': 36676,\n",
       " 'probably': 26235,\n",
       " \"composer's\": 7478,\n",
       " 'work': 37196,\n",
       " \"haven't\": 15659,\n",
       " 'heard': 15762,\n",
       " 'xenogears': 37432,\n",
       " \"can't\": 5676,\n",
       " 'sure': 32637,\n",
       " 'never': 22691,\n",
       " 'twice': 34781,\n",
       " 'wish': 37021,\n",
       " 'could': 8126,\n",
       " 'give': 14564,\n",
       " '6': 856,\n",
       " 'stars': 31797,\n",
       " 'excellent': 12150,\n",
       " 'truly': 34625,\n",
       " 'enjoy': 11608,\n",
       " 'video': 35973,\n",
       " 'most': 21973,\n",
       " 'here': 15941,\n",
       " \"it's\": 17979,\n",
       " 'relaxing': 27825,\n",
       " 'peaceful.on': 24626,\n",
       " 'disk': 10070,\n",
       " 'favorites': 12826,\n",
       " 'scars': 29309,\n",
       " 'between': 4178,\n",
       " 'life': 19613,\n",
       " 'death': 8996,\n",
       " 'forest': 13568,\n",
       " 'illusion': 16852,\n",
       " 'fortress': 13644,\n",
       " 'ancient': 2288,\n",
       " 'dragons': 10569,\n",
       " 'lost': 20068,\n",
       " 'fragment': 13714,\n",
       " 'drowned': 10695,\n",
       " 'valley.disk': 35714,\n",
       " 'two': 34799,\n",
       " 'draggons': 10561,\n",
       " 'galdorb': 14136,\n",
       " '-': 33,\n",
       " 'home': 16260,\n",
       " 'gale': 14137,\n",
       " 'girlfriend': 14551,\n",
       " 'likes': 19693,\n",
       " 'zelbessdisk': 37667,\n",
       " 'three': 33719,\n",
       " 'garden': 14225,\n",
       " 'god': 14686,\n",
       " 'chronopolis': 6660,\n",
       " 'fates': 12791,\n",
       " 'jellyfish': 18258,\n",
       " 'sea': 29542,\n",
       " 'burning': 5403,\n",
       " 'orphange': 23837,\n",
       " \"dragon's\": 10564,\n",
       " 'prayer': 25878,\n",
       " 'tower': 34228,\n",
       " 'dragon': 10563,\n",
       " 'radical': 26992,\n",
       " 'dreamers': 10617,\n",
       " 'unstealable': 35431,\n",
       " 'jewel.overall': 18297,\n",
       " 'should': 30273,\n",
       " 'brought': 5175,\n",
       " 'by': 5501,\n",
       " 'those': 33674,\n",
       " 'music.xander': 22276,\n",
       " 'remember': 27917,\n",
       " 'pull': 26646,\n",
       " 'jaw': 18204,\n",
       " 'off': 23406,\n",
       " 'floor': 13372,\n",
       " 'after': 1691,\n",
       " 'hearing': 15764,\n",
       " 'know': 18882,\n",
       " 'how': 16479,\n",
       " 'divine': 10257,\n",
       " 'single': 30541,\n",
       " 'song': 31161,\n",
       " 'tells': 33224,\n",
       " 'story': 32066,\n",
       " 'good': 14757,\n",
       " 'greatest': 15005,\n",
       " 'songs': 31173,\n",
       " 'without': 37056,\n",
       " 'doubt': 10492,\n",
       " 'magical': 20372,\n",
       " 'wind': 36960,\n",
       " 'unstolen': 35434,\n",
       " 'jewel': 18296,\n",
       " 'translation': 34377,\n",
       " 'varies': 35763,\n",
       " 'perfect': 24762,\n",
       " 'ask': 2943,\n",
       " 'can': 5675,\n",
       " 'mitsuda': 21647,\n",
       " 'just': 18523,\n",
       " 'poured': 25785,\n",
       " 'his': 16139,\n",
       " 'heart': 15767,\n",
       " 'wrote': 37379,\n",
       " 'paper': 24335,\n",
       " 'absolute': 1206,\n",
       " 'am': 2132,\n",
       " 'quite': 26922,\n",
       " 'actually': 1435,\n",
       " 'taking': 32969,\n",
       " 'read': 27283,\n",
       " 'at': 3055,\n",
       " 'least': 19366,\n",
       " 'once': 23560,\n",
       " 'few': 12975,\n",
       " 'whether': 36771,\n",
       " 'were': 36696,\n",
       " 'aware': 3333,\n",
       " 'or': 23738,\n",
       " 'not': 23051,\n",
       " 'contributed': 7870,\n",
       " 'greatly': 15008,\n",
       " 'mood': 21878,\n",
       " 'minute': 21505,\n",
       " 'whole': 36843,\n",
       " 'game.composed': 14155,\n",
       " '3': 617,\n",
       " 'cds': 6087,\n",
       " 'exact': 12107,\n",
       " 'count': 8144,\n",
       " 'heart-rendering': 15771,\n",
       " 'impressively': 17020,\n",
       " 'remarkable': 27899,\n",
       " 'assure': 3026,\n",
       " 'will': 36930,\n",
       " 'forget': 13583,\n",
       " 'everything': 12053,\n",
       " 'listener': 19814,\n",
       " 'fast-paced': 12770,\n",
       " 'energetic': 11554,\n",
       " 'dancing': 8830,\n",
       " 'tokage': 34032,\n",
       " 'termina': 33304,\n",
       " 'slower': 30830,\n",
       " 'haunting': 15645,\n",
       " 'purely': 26717,\n",
       " 'beautifully': 3854,\n",
       " 'composed': 7476,\n",
       " 'some': 31114,\n",
       " 'fantastic': 12702,\n",
       " 'vocals': 36140,\n",
       " 'videogame': 35977,\n",
       " 'soundtracks': 31298,\n",
       " 'there': 33523,\n",
       " 'surely': 32640,\n",
       " 'buyer': 5482,\n",
       " 'beware': 4186,\n",
       " 'self-published': 29726,\n",
       " 'book': 4665,\n",
       " 'want': 36324,\n",
       " 'why--read': 36865,\n",
       " 'paragraphs': 24362,\n",
       " '5': 794,\n",
       " 'written': 37363,\n",
       " 'ms': 22139,\n",
       " \"haddon's\": 15309,\n",
       " 'family': 12656,\n",
       " 'friends--or': 13852,\n",
       " 'perhaps': 24793,\n",
       " 'herself': 15978,\n",
       " 'imagine': 16885,\n",
       " 'thing--i': 33595,\n",
       " 'spent': 31460,\n",
       " 'evening': 12006,\n",
       " 'friend': 13846,\n",
       " 'we': 36504,\n",
       " 'hysterics': 16690,\n",
       " 'bits': 4326,\n",
       " 'pieces': 25091,\n",
       " 'another': 2428,\n",
       " 'definitely': 9177,\n",
       " 'bad': 3486,\n",
       " 'enough': 11634,\n",
       " 'entered': 11666,\n",
       " 'into': 17754,\n",
       " 'kind': 18768,\n",
       " 'worst': 37274,\n",
       " 'contest': 7824,\n",
       " 'believe': 4012,\n",
       " 'amazon': 2159,\n",
       " 'sells': 29750,\n",
       " 'thing': 33593,\n",
       " 'maybe': 20880,\n",
       " 'offer': 23433,\n",
       " 'them': 33463,\n",
       " '8th': 995,\n",
       " 'grade': 14876,\n",
       " 'term': 33301,\n",
       " 'kill': 18747,\n",
       " 'mockingbird': 21685,\n",
       " 'haddon': 15308,\n",
       " 'anyway': 2546,\n",
       " 'unless': 35289,\n",
       " 'send': 29785,\n",
       " 'someone': 31122,\n",
       " 'joke---stay': 18383,\n",
       " 'far': 12711,\n",
       " 'glorious': 14634,\n",
       " 'loved': 20115,\n",
       " 'whisper': 36808,\n",
       " 'wicked': 36876,\n",
       " 'saints': 29058,\n",
       " 'pleasantly': 25355,\n",
       " 'surprised': 32673,\n",
       " 'changes': 6236,\n",
       " 'normaly': 23025,\n",
       " 'romance': 28713,\n",
       " 'novels': 23133,\n",
       " 'world': 37237,\n",
       " 'raving': 27174,\n",
       " 'about': 1177,\n",
       " 'bought': 4863,\n",
       " 'brilliant': 5109,\n",
       " 'because': 3869,\n",
       " 'true': 34615,\n",
       " 'wonderful': 37138,\n",
       " 'told': 34035,\n",
       " 'friends': 13851,\n",
       " 'typical': 34834,\n",
       " 'crime': 8392,\n",
       " 'becuase': 3882,\n",
       " 'missing': 21599,\n",
       " 'warming': 36358,\n",
       " 'five': 13222,\n",
       " 'finished': 13125,\n",
       " 'fell': 12913,\n",
       " 'love': 20106,\n",
       " 'caracters': 5806,\n",
       " 'expected': 12299,\n",
       " 'average': 3293,\n",
       " 'instead': 17531,\n",
       " 'found': 13672,\n",
       " 'books': 4725,\n",
       " 'when': 36759,\n",
       " 'thought': 33682,\n",
       " 'predict': 25941,\n",
       " 'outcome': 23947,\n",
       " 'shocked': 30212,\n",
       " 'writting': 37367,\n",
       " 'descriptive': 9438,\n",
       " 'broke': 5149,\n",
       " \"julia's\": 18480,\n",
       " 'did': 9702,\n",
       " 'felt': 12921,\n",
       " 'reader': 27304,\n",
       " 'lover': 20125,\n",
       " 'then': 33494,\n",
       " \"don't\": 10408,\n",
       " 'let': 19506,\n",
       " 'cover': 8195,\n",
       " 'fool': 13495,\n",
       " 'spectacular': 31422,\n",
       " 'whispers': 36811,\n",
       " 'easy': 11028,\n",
       " 'made': 20342,\n",
       " 'keep': 18627,\n",
       " 'put': 26764,\n",
       " 'down.it': 10517,\n",
       " 'left': 19403,\n",
       " 'wanting': 36328,\n",
       " 'follow': 13469,\n",
       " 'coming': 7272,\n",
       " 'soon': 31197,\n",
       " 'used': 35601,\n",
       " 'gotten': 14840,\n",
       " 'again': 1709,\n",
       " 'very': 35915,\n",
       " 'enjoyable': 11610,\n",
       " 'complete': 7439,\n",
       " 'waste': 36417,\n",
       " 'typographical': 34839,\n",
       " 'errors': 11848,\n",
       " 'poor': 25589,\n",
       " 'grammar': 14906,\n",
       " 'totally': 34186,\n",
       " 'pathetic': 24533,\n",
       " 'plot': 25386,\n",
       " 'add': 1467,\n",
       " 'up': 35489,\n",
       " 'nothing': 23086,\n",
       " 'embarrassed': 11378,\n",
       " 'author': 3221,\n",
       " 'disappointed': 9921,\n",
       " 'paid': 24243,\n",
       " 'great': 14994,\n",
       " 'fast': 12766,\n",
       " 'boy': 4915,\n",
       " 'what': 36732,\n",
       " 'twist': 34794,\n",
       " 'turns': 34734,\n",
       " 'keeps': 18631,\n",
       " 'guessing': 15185,\n",
       " 'happen': 15476,\n",
       " 'next': 22733,\n",
       " 'makes': 20447,\n",
       " 'fall': 12629,\n",
       " 'heat': 15799,\n",
       " 'also': 2087,\n",
       " 'make': 20436,\n",
       " 'angery': 2344,\n",
       " 'go': 14669,\n",
       " 'throu': 33744,\n",
       " 'several': 29953,\n",
       " 'emotions': 11432,\n",
       " 'quick': 26884,\n",
       " 'something': 31131,\n",
       " 'end': 11508,\n",
       " 'day': 8932,\n",
       " 'night': 22781,\n",
       " 'yet': 37544,\n",
       " 'realistic': 27340,\n",
       " 'showed': 30297,\n",
       " 'error': 11847,\n",
       " 'human': 16545,\n",
       " 'fact': 12551,\n",
       " 'writer': 37349,\n",
       " 'loving': 20134,\n",
       " 'side': 30368,\n",
       " 'revengeful': 28353,\n",
       " 'him': 16106,\n",
       " 'twisted': 34796,\n",
       " 'turned': 34728,\n",
       " 'glass': 14591,\n",
       " 'castle': 5968,\n",
       " 'oh': 23464,\n",
       " 'please': 25357,\n",
       " 'guess': 15182,\n",
       " 'novel': 23121,\n",
       " 'discerning': 9951,\n",
       " 'others': 23882,\n",
       " 'drivel': 10664,\n",
       " 'trouble': 34590,\n",
       " 'typo': 34838,\n",
       " 'prominently': 26388,\n",
       " 'featured': 12859,\n",
       " 'back': 3444,\n",
       " 'first': 13179,\n",
       " 'page': 24236,\n",
       " 'removed': 27954,\n",
       " 'wait': 36256,\n",
       " 'point': 25472,\n",
       " 're-read': 27246,\n",
       " 'beginning': 3954,\n",
       " 'clear': 6857,\n",
       " 'intentional': 17624,\n",
       " 'churning': 6686,\n",
       " 'over-heated': 24019,\n",
       " 'prose': 26463,\n",
       " 'satiric': 29191,\n",
       " 'purposes': 26743,\n",
       " 'phew': 24959,\n",
       " 'glad': 14576,\n",
       " \"didn't\": 9715,\n",
       " '$': 19,\n",
       " '10.95': 136,\n",
       " 'awful': 3352,\n",
       " 'beyond': 4192,\n",
       " 'belief': 4007,\n",
       " 'wasting': 36423,\n",
       " 'their': 33456,\n",
       " 'seems': 29649,\n",
       " '7th': 953,\n",
       " 'grader': 14878,\n",
       " 'grammatical': 14907,\n",
       " 'skills': 30673,\n",
       " 'her': 15923,\n",
       " 'age': 1733,\n",
       " 'reviewer': 28372,\n",
       " 'points': 25482,\n",
       " 'misspelling': 21613,\n",
       " 'per': 24738,\n",
       " 'chapter': 6263,\n",
       " 'example': 12128,\n",
       " 'mentioned': 21181,\n",
       " 'she': 30094,\n",
       " 'had': 15304,\n",
       " 'lean': 19341,\n",
       " 'house': 16461,\n",
       " 'distracted': 10201,\n",
       " 'writing': 37357,\n",
       " 'weak': 36509,\n",
       " 'decided': 9059,\n",
       " 'pencil': 24696,\n",
       " 'hand': 15400,\n",
       " 'mark': 20668,\n",
       " 'horrible': 16381,\n",
       " 'spelling': 31451,\n",
       " 'too': 34090,\n",
       " \"author's\": 3222,\n",
       " 'relatives': 27817,\n",
       " 'faith': 12612,\n",
       " 'try': 34648,\n",
       " 'us': 35575,\n",
       " 'fake': 12620,\n",
       " 'glaringly': 14589,\n",
       " 'obvious': 23319,\n",
       " 'glowing': 14646,\n",
       " 'same': 29096,\n",
       " 'person': 24858,\n",
       " 'they': 33564,\n",
       " 'misspellings': 21614,\n",
       " 'sentence': 29827,\n",
       " 'structure': 32228,\n",
       " 'veronica': 35887,\n",
       " 'think': 33603,\n",
       " '?': 1074,\n",
       " 'romantic': 28721,\n",
       " 'zen': 37671,\n",
       " 'baseball': 3676,\n",
       " 'comedy': 7240,\n",
       " 'hear': 15760,\n",
       " 'folks': 13463,\n",
       " 'em': 11352,\n",
       " 'anymore': 2534,\n",
       " 'might': 21376,\n",
       " 'talking': 32987,\n",
       " 'cool': 7961,\n",
       " 'young': 37592,\n",
       " 'cuban': 8568,\n",
       " 'searching': 29567,\n",
       " 'idenity': 16750,\n",
       " 'stumbles': 32281,\n",
       " 'coastal': 7029,\n",
       " 'resort': 28190,\n",
       " 'kitchen': 18816,\n",
       " 'gig': 14494,\n",
       " 'motorcycle': 22019,\n",
       " 'maintenance': 20425,\n",
       " 'man': 20498,\n",
       " 'hysterical': 16688,\n",
       " 'italian': 18045,\n",
       " 'chefs': 6432,\n",
       " 'latino': 19212,\n",
       " 'fireballing': 13150,\n",
       " 'right': 28513,\n",
       " 'handed': 15409,\n",
       " 'pitcher': 25186,\n",
       " 'plays': 25343,\n",
       " 'team': 33118,\n",
       " 'sponsored': 31566,\n",
       " \"resort's\": 28191,\n",
       " 'owner': 24163,\n",
       " 'often': 23455,\n",
       " 'case': 5935,\n",
       " 'finds': 13098,\n",
       " 'through': 33745,\n",
       " 'honest': 16297,\n",
       " 'comical': 7267,\n",
       " 'always': 2128,\n",
       " 'emotional': 11428,\n",
       " 'interaction': 17636,\n",
       " 'sizzling': 30629,\n",
       " 'roster': 28781,\n",
       " 'players': 25331,\n",
       " 'mix': 21650,\n",
       " 'special': 31395,\n",
       " 'effects': 11164,\n",
       " 'salsa': 29080,\n",
       " 'flashbacks': 13268,\n",
       " 'gets': 14441,\n",
       " '4': 705,\n",
       " 'big': 4223,\n",
       " 'fashionable': 12760,\n",
       " 'compression': 7503,\n",
       " 'stockings': 32008,\n",
       " 'dvt': 10881,\n",
       " 'doctor': 10315,\n",
       " 'required': 28121,\n",
       " 'wear': 36522,\n",
       " 'wore': 37195,\n",
       " 'ugly': 34883,\n",
       " 'white': 36816,\n",
       " 'ted': 33167,\n",
       " 'hose': 16415,\n",
       " 'yucky': 37631,\n",
       " 'thick': 33578,\n",
       " 'brown': 5178,\n",
       " 'jobst': 18353,\n",
       " 'ultrasheer': 34909,\n",
       " 'gave': 14286,\n",
       " 'needed': 22588,\n",
       " '15-20': 251,\n",
       " 'looked': 20015,\n",
       " 'regular': 27743,\n",
       " 'pantyhose': 24332,\n",
       " 'though': 33677,\n",
       " 'blood': 4473,\n",
       " 'clot': 6973,\n",
       " 'gone': 14750,\n",
       " 'still': 31969,\n",
       " 'these': 33553,\n",
       " 'support': 32606,\n",
       " 'legs': 19443,\n",
       " 'nice': 22743,\n",
       " '*': 30,\n",
       " 'note': 23072,\n",
       " 'problems': 26251,\n",
       " 'rubberized': 28851,\n",
       " 'tops': 34134,\n",
       " 'rolling': 28707,\n",
       " 'thigh': 33585,\n",
       " 'tried': 34511,\n",
       " 'adhesive': 1505,\n",
       " 'hated': 15626,\n",
       " 'having': 15663,\n",
       " 'skin': 30682,\n",
       " 'pulled': 26647,\n",
       " 'inexpensive': 17273,\n",
       " 'garter': 14248,\n",
       " 'belt': 4051,\n",
       " 'works': 37229,\n",
       " 'fine': 13099,\n",
       " 'helps': 15899,\n",
       " 'high': 16033,\n",
       " 'product': 26285,\n",
       " 'however': 16489,\n",
       " 'difficult': 9766,\n",
       " 'get': 14431,\n",
       " 'older': 23502,\n",
       " \"i've\": 16699,\n",
       " 'full': 13955,\n",
       " 'workout': 37226,\n",
       " 'getting': 14443,\n",
       " 'wears': 36530,\n",
       " 'begin': 3944,\n",
       " 'roll': 28694,\n",
       " 'top': 34113,\n",
       " 'create': 8325,\n",
       " 'deep': 9111,\n",
       " 'ridge': 28494,\n",
       " 'difficulties': 9767,\n",
       " 'addressed': 1491,\n",
       " 'such': 32431,\n",
       " 'help': 15885,\n",
       " 'sizes': 30626,\n",
       " 'recomended': 27494,\n",
       " 'size': 30622,\n",
       " 'chart': 6350,\n",
       " 'real': 27324,\n",
       " 'smaller': 30856,\n",
       " 'than': 33400,\n",
       " 'sheer': 30111,\n",
       " 'item': 18060,\n",
       " 'internet': 17693,\n",
       " '..': 45,\n",
       " 'better': 4159,\n",
       " 'store': 32047,\n",
       " 'check': 6396,\n",
       " 'mens': 21172,\n",
       " 'model': 21692,\n",
       " 'may': 20878,\n",
       " 'ok': 23476,\n",
       " 'sedentary': 29620,\n",
       " 'types': 34830,\n",
       " 'active': 1416,\n",
       " 'around': 2827,\n",
       " 'alot': 2073,\n",
       " 'job': 18346,\n",
       " 'consistently': 7740,\n",
       " 'rolled': 28698,\n",
       " 'ankles': 2379,\n",
       " 'solution': 31103,\n",
       " 'standard': 31749,\n",
       " 'stocking': 32007,\n",
       " '20-30': 468,\n",
       " 'stock': 32003,\n",
       " '#114622': 6,\n",
       " 'stays': 31873,\n",
       " 'gives': 14570,\n",
       " 'need': 22586,\n",
       " 'both': 4844,\n",
       " 'pair': 24266,\n",
       " 'tore': 34139,\n",
       " 'struggled': 32235,\n",
       " 'riddance': 28482,\n",
       " '/': 51,\n",
       " 'investment': 17833,\n",
       " 'delicious': 9249,\n",
       " 'cookie': 7956,\n",
       " 'funny': 14016,\n",
       " 'knowing': 18891,\n",
       " 'header': 15725,\n",
       " 'quickly': 26894,\n",
       " 'packaged': 24209,\n",
       " 'cookies': 7957,\n",
       " 'no': 22857,\n",
       " 'noticed': 23096,\n",
       " 'since': 30519,\n",
       " 'title.this': 33967,\n",
       " 'baking': 3522,\n",
       " 'convenience': 7895,\n",
       " 'dough': 10497,\n",
       " 'wrapped': 37311,\n",
       " 'plastic': 25282,\n",
       " 'logs': 19971,\n",
       " 'surprise': 32671,\n",
       " 'mixing': 21657,\n",
       " 'messy': 21248,\n",
       " 'extremely': 12471,\n",
       " 'sticky': 31960,\n",
       " 'flexibility': 13328,\n",
       " 'ratio': 27146,\n",
       " 'ingredients': 17348,\n",
       " 'extra': 12454,\n",
       " 'butter': 5459,\n",
       " 'baked': 3518,\n",
       " 'chewy': 6472,\n",
       " 'really': 27356,\n",
       " 'large': 19160,\n",
       " 'chocolate': 6568,\n",
       " 'chips': 6544,\n",
       " 'it--i': 17981,\n",
       " 'addition': 1479,\n",
       " 'natural': 22495,\n",
       " 'flavors': 13304,\n",
       " 'abysmal': 1241,\n",
       " 'digital': 9786,\n",
       " 'copy': 7995,\n",
       " 'rather': 27143,\n",
       " 'scratches': 29474,\n",
       " 'insect': 17448,\n",
       " 'droppings': 10689,\n",
       " 'random': 27079,\n",
       " 'pixelations': 25208,\n",
       " 'combined': 7222,\n",
       " 'muddy': 22179,\n",
       " 'light': 19653,\n",
       " 'vague': 35692,\n",
       " 'image': 16873,\n",
       " 'resolution': 28179,\n",
       " 'cue': 8580,\n",
       " 'packaging': 24211,\n",
       " 'straight': 32101,\n",
       " 'street': 32156,\n",
       " 'corner': 8035,\n",
       " 'bootleg': 4765,\n",
       " 'dealer.if': 8984,\n",
       " 'seen': 29651,\n",
       " 'reasonably': 27386,\n",
       " 'condition': 7597,\n",
       " 'film': 13052,\n",
       " 'defining': 9174,\n",
       " 'visuals': 36106,\n",
       " 'crystal': 8552,\n",
       " 'lighting': 19666,\n",
       " 'contrasts': 7868,\n",
       " 'black': 4347,\n",
       " 'surrounding': 32689,\n",
       " 'countryside': 8165,\n",
       " 'old': 23493,\n",
       " 'scenes': 29336,\n",
       " 'set': 29919,\n",
       " 'early': 10974,\n",
       " 'morning': 21944,\n",
       " 'ground': 15109,\n",
       " 'mists': 21631,\n",
       " 'haze': 15693,\n",
       " 'memory': 21151,\n",
       " 'while': 36776,\n",
       " 'events': 12012,\n",
       " 'bridge': 5086,\n",
       " 'water': 36443,\n",
       " 'bright': 5095,\n",
       " 'immediate.here': 16918,\n",
       " 'dull': 10781,\n",
       " 'dark': 8871,\n",
       " 'clouded': 6981,\n",
       " 'timbre': 33862,\n",
       " 'enunciation': 11727,\n",
       " \"captain's\": 5778,\n",
       " 'commands': 7283,\n",
       " 'visuals.after': 36108,\n",
       " 'hard': 15513,\n",
       " 'award': 3328,\n",
       " 'winning': 36983,\n",
       " 'critically': 8435,\n",
       " 'acclaimed': 1287,\n",
       " \"film's\": 13053,\n",
       " 'presentation': 26042,\n",
       " 'youtube': 37620,\n",
       " 'somewhere': 31144,\n",
       " 'dvd': 10859,\n",
       " 'comes': 7248,\n",
       " '16mm': 282,\n",
       " 'public': 26607,\n",
       " 'library': 19582,\n",
       " 'reel.just': 27624,\n",
       " 'none': 22978,\n",
       " 'appear': 2626,\n",
       " 'fascinating': 12754,\n",
       " 'insight': 17463,\n",
       " 'modern': 21703,\n",
       " 'japanese': 18185,\n",
       " 'teens': 33186,\n",
       " 'thoroughly': 33670,\n",
       " 'enjoyed': 11612,\n",
       " 'rising': 28565,\n",
       " 'sons': 31190,\n",
       " 'daughters': 8913,\n",
       " 'other': 23871,\n",
       " 'looks': 20020,\n",
       " 'society': 31029,\n",
       " 'view': 35992,\n",
       " 'poised': 25486,\n",
       " 'parents': 24396,\n",
       " 'age-old': 1734,\n",
       " 'culture': 8597,\n",
       " 'restraint': 28252,\n",
       " 'obedience': 23269,\n",
       " 'community': 7345,\n",
       " 'peers': 24669,\n",
       " 'adulation': 1575,\n",
       " 'western': 36709,\n",
       " 'form': 13599,\n",
       " 'new': 22699,\n",
       " 'japan': 18183,\n",
       " 'seem': 29642,\n",
       " 'creating': 8333,\n",
       " 'international': 17689,\n",
       " 'blend': 4423,\n",
       " 'ando': 2306,\n",
       " 'demonstrates': 9328,\n",
       " 'vignettes': 36014,\n",
       " 'private': 26214,\n",
       " 'lives': 19876,\n",
       " 'members': 21136,\n",
       " 'steven': 31947,\n",
       " 'wardell': 36338,\n",
       " 'clearly': 6866,\n",
       " 'talented': 32977,\n",
       " 'adopted': 1556,\n",
       " 'schooling': 29392,\n",
       " 'four': 13683,\n",
       " 'thus': 33791,\n",
       " 'able': 1162,\n",
       " 'inside': 17461,\n",
       " 'liked': 19688,\n",
       " 'album': 1909,\n",
       " 'o': 23247,\n",
       " 'listened': 19813,\n",
       " 'blue': 4508,\n",
       " 'angel': 2331,\n",
       " 'lanna': 19140,\n",
       " 'mama': 20491,\n",
       " 'hair': 15333,\n",
       " 'rose': 28770,\n",
       " 'neck.roy': 22577,\n",
       " 'trully': 34624,\n",
       " 'singer': 30534,\n",
       " 'talent': 32973,\n",
       " 'find': 13093,\n",
       " 'days': 8944,\n",
       " 'problem': 26244,\n",
       " 'charging': 6327,\n",
       " 'aaas': 1120,\n",
       " 'charger': 6321,\n",
       " 'charges': 6326,\n",
       " 'aa': 1116,\n",
       " 'batteries': 3748,\n",
       " 'huge': 16532,\n",
       " 'securing': 29617,\n",
       " 'aaa': 1117,\n",
       " 'charge': 6317,\n",
       " 'flip': 13351,\n",
       " 'little': 19851,\n",
       " 'button': 5466,\n",
       " 'positive': 25692,\n",
       " 'pop': 25598,\n",
       " \"won't\": 37133,\n",
       " 'hold': 16222,\n",
       " 'mechanism': 21035,\n",
       " 'became': 3863,\n",
       " 'loose': 20035,\n",
       " 'horizontal': 16366,\n",
       " 'pressure': 26071,\n",
       " 'push': 26753,\n",
       " 'buttons': 5469,\n",
       " 'do': 10290,\n",
       " 'using': 35627,\n",
       " 'duct': 10754,\n",
       " 'tape': 33030,\n",
       " 'segment': 29663,\n",
       " 'crayon': 8306,\n",
       " 'apply': 2662,\n",
       " 'wrap': 37309,\n",
       " 'painful': 24249,\n",
       " 'advertised': 1612,\n",
       " 'chargers': 6324,\n",
       " 'instructions': 17556,\n",
       " 'lights': 19674,\n",
       " 'stay': 31865,\n",
       " 'battery': 3750,\n",
       " '...': 47,\n",
       " 'dont': 10425,\n",
       " 'turn': 34726,\n",
       " 'done': 10416,\n",
       " '24': 534,\n",
       " 'hours': 16458,\n",
       " 'returned': 28321,\n",
       " 'thinking': 33609,\n",
       " 'unit.the': 35263,\n",
       " 'kept': 18664,\n",
       " 'does': 10348,\n",
       " 'useless': 35614,\n",
       " 'backup': 3477,\n",
       " 'manage': 20508,\n",
       " 'drain': 10573,\n",
       " 'aas': 1125,\n",
       " \"wouldn't\": 37296,\n",
       " 'purchase': 26703,\n",
       " 'convenient': 7896,\n",
       " 'lasts': 19192,\n",
       " 'short': 30245,\n",
       " 'longer': 20002,\n",
       " 'kodak': 18909,\n",
       " 'nimh': 22820,\n",
       " 'dear': 8992,\n",
       " 'excited': 12182,\n",
       " 'ostensibly': 23863,\n",
       " 'muslim': 22299,\n",
       " 'feminism': 12931,\n",
       " 'volume': 36167,\n",
       " 'live': 19861,\n",
       " 'expectations.one': 12297,\n",
       " 'essay': 11894,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check vocabulary\n",
    "\n",
    "bow_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that vocabulary is the same for all vectorizers\n",
    "\n",
    "bow_vectorizer.vocabulary_ == ohe_vectorizer.vocabulary_ == tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!', '\"', '#', '#10', '#10162', '#11', '#114622', '#12', '#13', '#15')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort tokens in ascending order of the vocabulary values\n",
    "\n",
    "_, tokens = zip(*sorted(zip(bow_vectorizer.vocabulary_.values(), bow_vectorizer.vocabulary_.keys())))\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '#10', '#10162', '#11', '#114622', '#12', '#13', '#15']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use the get_feature_names() method to access these tokens\n",
    "\n",
    "bow_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "\n",
    "df_cv_bow = pd.DataFrame(cv_bow.toarray(), columns=tokens)\n",
    "df_cv_ohe = pd.DataFrame(cv_ohe.toarray(), columns=tokens)\n",
    "df_tfidf = pd.DataFrame(tfidf.toarray(), columns=tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#10</th>\n",
       "      <th>#10162</th>\n",
       "      <th>#11</th>\n",
       "      <th>#114622</th>\n",
       "      <th>#12</th>\n",
       "      <th>#13</th>\n",
       "      <th>#15</th>\n",
       "      <th>...</th>\n",
       "      <th>à</th>\n",
       "      <th>ángel</th>\n",
       "      <th>è</th>\n",
       "      <th>émouvantes</th>\n",
       "      <th>étai</th>\n",
       "      <th>étre</th>\n",
       "      <th>éviter</th>\n",
       "      <th>única</th>\n",
       "      <th>﻿</th>\n",
       "      <th>�</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   !   \"  #  #10  #10162  #11  #114622  #12  #13  #15 ...  à  ángel  è  \\\n",
       "0  4   0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "1  0   0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "2  1  12  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "3  0   0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "4  2   0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "\n",
       "   émouvantes  étai  étre  éviter  única  ﻿  �  \n",
       "0           0     0     0       0      0  0  0  \n",
       "1           0     0     0       0      0  0  0  \n",
       "2           0     0     0       0      0  0  0  \n",
       "3           0     0     0       0      0  0  0  \n",
       "4           0     0     0       0      0  0  0  \n",
       "\n",
       "[5 rows x 37767 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 37767)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#10</th>\n",
       "      <th>#10162</th>\n",
       "      <th>#11</th>\n",
       "      <th>#114622</th>\n",
       "      <th>#12</th>\n",
       "      <th>#13</th>\n",
       "      <th>#15</th>\n",
       "      <th>...</th>\n",
       "      <th>à</th>\n",
       "      <th>ángel</th>\n",
       "      <th>è</th>\n",
       "      <th>émouvantes</th>\n",
       "      <th>étai</th>\n",
       "      <th>étre</th>\n",
       "      <th>éviter</th>\n",
       "      <th>única</th>\n",
       "      <th>﻿</th>\n",
       "      <th>�</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   !  \"  #  #10  #10162  #11  #114622  #12  #13  #15 ...  à  ángel  è  \\\n",
       "0  1  0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "1  0  0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "2  1  1  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "3  0  0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "4  1  0  0    0       0    0        0    0    0    0 ...  0      0  0   \n",
       "\n",
       "   émouvantes  étai  étre  éviter  única  ﻿  �  \n",
       "0           0     0     0       0      0  0  0  \n",
       "1           0     0     0       0      0  0  0  \n",
       "2           0     0     0       0      0  0  0  \n",
       "3           0     0     0       0      0  0  0  \n",
       "4           0     0     0       0      0  0  0  \n",
       "\n",
       "[5 rows x 37767 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 37767)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>#10</th>\n",
       "      <th>#10162</th>\n",
       "      <th>#11</th>\n",
       "      <th>#114622</th>\n",
       "      <th>#12</th>\n",
       "      <th>#13</th>\n",
       "      <th>#15</th>\n",
       "      <th>...</th>\n",
       "      <th>à</th>\n",
       "      <th>ángel</th>\n",
       "      <th>è</th>\n",
       "      <th>émouvantes</th>\n",
       "      <th>étai</th>\n",
       "      <th>étre</th>\n",
       "      <th>éviter</th>\n",
       "      <th>única</th>\n",
       "      <th>﻿</th>\n",
       "      <th>�</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029174</td>\n",
       "      <td>0.430374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37767 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !         \"    #  #10  #10162  #11  #114622  #12  #13  #15 ...   \\\n",
       "0  0.166660  0.000000  0.0  0.0     0.0  0.0      0.0  0.0  0.0  0.0 ...    \n",
       "1  0.000000  0.000000  0.0  0.0     0.0  0.0      0.0  0.0  0.0  0.0 ...    \n",
       "2  0.029174  0.430374  0.0  0.0     0.0  0.0      0.0  0.0  0.0  0.0 ...    \n",
       "3  0.000000  0.000000  0.0  0.0     0.0  0.0      0.0  0.0  0.0  0.0 ...    \n",
       "4  0.081502  0.000000  0.0  0.0     0.0  0.0      0.0  0.0  0.0  0.0 ...    \n",
       "\n",
       "     à  ángel    è  émouvantes  étai  étre  éviter  única    ﻿    �  \n",
       "0  0.0    0.0  0.0         0.0   0.0   0.0     0.0    0.0  0.0  0.0  \n",
       "1  0.0    0.0  0.0         0.0   0.0   0.0     0.0    0.0  0.0  0.0  \n",
       "2  0.0    0.0  0.0         0.0   0.0   0.0     0.0    0.0  0.0  0.0  \n",
       "3  0.0    0.0  0.0         0.0   0.0   0.0     0.0    0.0  0.0  0.0  \n",
       "4  0.0    0.0  0.0         0.0   0.0   0.0     0.0    0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 37767 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 37767)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our 10 000 reviews, we have a total of 37767 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit a Naive Bayes model, predict and evaluate the results for the different vectorization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: 0.832\n",
      "One-hot encoding: 0.832\n",
      "TF-IDF: 0.815\n"
     ]
    }
   ],
   "source": [
    "vec_methods = {'BoW': cv_bow, 'One-hot encoding': cv_ohe, 'TF-IDF': tfidf}\n",
    "\n",
    "for method, vec in vec_methods.items():\n",
    "    \n",
    "    # split training data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vec, df['label'], test_size=0.3, random_state=42)\n",
    "    \n",
    "    # fit\n",
    "    my_model = MultinomialNB()\n",
    "    my_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    predicted_sentiment = my_model.predict(X_test)\n",
    "    \n",
    "    # accuracy score\n",
    "    print(f\"{method}: {accuracy_score(y_test, predicted_sentiment)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer's BoW and one-hot encoding methods result in a slight improvement of our model's accuracy. Let's try to improve it even further with the help of **n-grams**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Vectorize text: Bow with n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_bow_vectorizer = CountVectorizer(tokenizer=casual_tokenize, ngram_range=(1,2))\n",
    "cv_ngrams_bow = ngrams_bow_vectorizer.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Fit a Naive Bayes model, predict and evaluate the result using n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW with n-grams: 0.8596666666666667\n"
     ]
    }
   ],
   "source": [
    "# split training data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cv_ngrams_bow, df['label'], test_size=0.3, random_state=42)\n",
    "    \n",
    "# fit\n",
    "my_model = MultinomialNB()\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predicted_sentiment = my_model.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print(f\"BoW with n-grams: {accuracy_score(y_test, predicted_sentiment)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering both **unigrams and bigrams**, our Naive Bayes model was able to correctly identify about **86%** of the reviews of the test set as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try to **tune the hyperparameter alpha** of our Naive Bayes model. We'll do this with sklearn's GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Tune hyperparameter alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'alpha': [0.1, 0.3, 0.4, 0.5, 1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'alpha': [0.1, 0.3, 0.4, 0.5, 1]}]\n",
    "\n",
    "my_model = MultinomialNB()\n",
    "\n",
    "grid_search = GridSearchCV(my_model, param_grid, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.4}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Retrain Naive Bayes model with tuned alpha hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW with n-grams: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "my_model = MultinomialNB(alpha=0.4)\n",
    "my_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predicted_sentiment = my_model.predict(X_test)\n",
    "\n",
    "# accuracy score\n",
    "print(f\"BoW with n-grams: {accuracy_score(y_test, predicted_sentiment)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to slightly improve our model. Our final accuracy score is now close to **0.87**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
